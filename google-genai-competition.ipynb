{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c5c1a4",
   "metadata": {
    "papermill": {
     "duration": 0.006323,
     "end_time": "2025-04-12T22:19:12.656389",
     "exception": false,
     "start_time": "2025-04-12T22:19:12.650066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scientific Paper Recommendation System with RAG\n",
    "## Project Description\n",
    "This project implements a Retrieval Augmented Generation (RAG) system for scientific paper recommendations. The system allows users to input a document or query and receive recommendations for relevant scientific papers from the ArXiv database.\n",
    "\n",
    "## Key Components\n",
    "Vector Database: Uses a ChromaDB vector database containing embeddings of 10,000 ArXiv research papers\n",
    "Document Processing: Extracts and processes PDF content using PyMuPDF\n",
    "Semantic Search: Performs similarity searches based on document content\n",
    "\n",
    "## GenAI Functionalities\n",
    "- Embeddings: Generates semantic embeddings using Google's text-embedding-004 model\n",
    "- Prompt Engineering: Utilizes carefully crafted prompts to guide the AI's behavior\n",
    "- RAG Implementation: Combines vector search results with generative AI responses\n",
    "- Document Understanding: Processes and interprets PDF research papers\n",
    "- Vector Embedding and Vector Search: Performs semantic similarity searches in high-dimensional vector space\n",
    "\n",
    "The system orchestrates these components through a chatbot interface that processes user queries, searches for relevant papers, and generates comprehensive responses that include paper details like authors and publication dates.\n",
    "\n",
    "## Database\n",
    "ArXiv serves as an excellent data source for our recommendation system for several key reasons:\n",
    "\n",
    "- **Rich Scientific Content**: Contains over 2 million scholarly articles across multiple disciplines\n",
    "- **Well-Structured Metadata**: Includes titles, abstracts, authors, and categories in a consistent format\n",
    "- **Embedding-Friendly**: Abstracts provide concise, information-dense text that produces meaningful vector embeddings\n",
    "- **Research Relevance**: Widely used by the scientific community, ensuring practical utility\n",
    "- **Semantic Search Compatibility**: Content structure works effectively with our embedding model (text-embedding-004)\n",
    "\n",
    "Our implementation uses 10,000 ArXiv papers converted to vector embeddings and stored in ChromaDB, enabling semantic similarity searches to retrieve relevant scientific literature for user queries. The Arxiv dataset is available in Kagggle with the following link: [Arxiv_dataset](https://www.kaggle.com/datasets/Cornell-University/arxiv). \n",
    "## Use Case\n",
    "Researchers can upload a scientific paper and ask questions to find related work in the ArXiv database, facilitating literature reviews and discovery of relevant research.\n",
    "\n",
    "````\n",
    "chatbot = RAG_Scientific_chatbot()\n",
    "answer = chatbot.chat(\"Find me related papers\", \"/path/to/document.pdf\")\n",
    "display(Markdown(answer))\n",
    "```` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb49df",
   "metadata": {
    "papermill": {
     "duration": 0.005271,
     "end_time": "2025-04-12T22:19:12.667681",
     "exception": false,
     "start_time": "2025-04-12T22:19:12.662410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "Import and install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e57372",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:19:12.679970Z",
     "iopub.status.busy": "2025-04-12T22:19:12.679467Z",
     "iopub.status.idle": "2025-04-12T22:20:11.047309Z",
     "shell.execute_reply": "2025-04-12T22:20:11.046088Z"
    },
    "papermill": {
     "duration": 58.376519,
     "end_time": "2025-04-12T22:20:11.049580",
     "exception": false,
     "start_time": "2025-04-12T22:19:12.673061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCollecting pymupdf\r\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\r\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pymupdf\r\n",
      "Successfully installed pymupdf-1.25.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n",
    "!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n",
    "!pip install --upgrade pymupdf\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05dc74c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:20:11.067976Z",
     "iopub.status.busy": "2025-04-12T22:20:11.067385Z",
     "iopub.status.idle": "2025-04-12T22:20:11.550556Z",
     "shell.execute_reply": "2025-04-12T22:20:11.549445Z"
    },
    "papermill": {
     "duration": 0.494445,
     "end_time": "2025-04-12T22:20:11.552566",
     "exception": false,
     "start_time": "2025-04-12T22:20:11.058121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API keys\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734e0b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:20:11.570477Z",
     "iopub.status.busy": "2025-04-12T22:20:11.570162Z",
     "iopub.status.idle": "2025-04-12T22:20:11.876251Z",
     "shell.execute_reply": "2025-04-12T22:20:11.874920Z"
    },
    "papermill": {
     "duration": 0.317362,
     "end_time": "2025-04-12T22:20:11.878353",
     "exception": false,
     "start_time": "2025-04-12T22:20:11.560991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a retry policy. The model might make multiple consecutive calls automatically\n",
    "# for a complex query, this ensures the client retries if it hits quota limits.\n",
    "from google.api_core import retry\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "if not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n",
    "  genai.models.Models.generate_content = retry.Retry(\n",
    "      predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f02e0",
   "metadata": {
    "papermill": {
     "duration": 0.009169,
     "end_time": "2025-04-12T22:20:11.897206",
     "exception": false,
     "start_time": "2025-04-12T22:20:11.888037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Upload of Arxiv papers\n",
    "First import the arxiv dataset and then perform vector embedding of all the documents. After the vector embedding, it is saved in a chromadb vector database. The arxiv dataset import is shown below.\n",
    "\n",
    "RANDOM SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9babfe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:20:11.916427Z",
     "iopub.status.busy": "2025-04-12T22:20:11.915909Z",
     "iopub.status.idle": "2025-04-12T22:22:40.794556Z",
     "shell.execute_reply": "2025-04-12T22:22:40.793043Z"
    },
    "papermill": {
     "duration": 148.901517,
     "end_time": "2025-04-12T22:22:40.807743",
     "exception": false,
     "start_time": "2025-04-12T22:20:11.906226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "amount_papers = 10000\n",
    "papers = []\n",
    "\n",
    "with open('/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        papers.append(json.loads(line))\n",
    "\n",
    "random_indices = set(random.sample(range(len(papers)), amount_papers))\n",
    "random_indices = list(random_indices)\n",
    "papers_random = []\n",
    "for i in range(len(random_indices)):\n",
    "    index = random_indices[i]\n",
    "    papers_random.append(papers[index])\n",
    "papers = papers_random\n",
    "# Now data is a list of dictionaries\n",
    "print(\"Headers:\", list(papers[0].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae181b3",
   "metadata": {
    "papermill": {
     "duration": 0.016116,
     "end_time": "2025-04-12T22:22:40.835298",
     "exception": false,
     "start_time": "2025-04-12T22:22:40.819182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Only the title and the abstract of each paper will be embedded. The code below implements this preprocessing of the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd455ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:22:41.117381Z",
     "iopub.status.busy": "2025-04-12T22:22:41.116910Z",
     "iopub.status.idle": "2025-04-12T22:22:41.311747Z",
     "shell.execute_reply": "2025-04-12T22:22:41.310626Z"
    },
    "papermill": {
     "duration": 0.469287,
     "end_time": "2025-04-12T22:22:41.313454",
     "exception": false,
     "start_time": "2025-04-12T22:22:40.844167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESSFULLY PREPROCESSED 10000 PAPERS\n",
      "--- EXAMPLE OF PREPROCESSED PAPER ---\n",
      "PAPER TITLE: Lorentzian Lie 3-algebras and their Bagger-Lambert moduli space\n",
      "PAPER CONTENT:   We classify Lie 3-algebras possessing an invariant lorentzian inner product. The indecomposable objects are in one-to-one correspondence with compact real forms of metric semisimple Lie algebras. We analyse the moduli space of classical vacua of the Bagger-Lambert theory corresponding to these Lie 3-algebras. We establish a one-to-one correspondence between one branch of the moduli space and compact riemannian symmetric spaces. We analyse the asymptotic behaviour of the moduli space and identify a large class of models with moduli branches exhibiting the desired N^{3/2} behaviour. \n"
     ]
    }
   ],
   "source": [
    "def remove_newlines(obj):\n",
    "    if isinstance(obj, str):\n",
    "        return obj.replace('\\n', ' ')\n",
    "        \n",
    "preprocessed_papers = []\n",
    "for paper in papers:\n",
    "    preprocessed_papers.append(\"PAPER TITLE: \" + remove_newlines(paper[\"title\"]) + \"\\nPAPER CONTENT: \"+ remove_newlines(paper[\"abstract\"]))\n",
    "print(\"SUCCESSFULLY PREPROCESSED \"+ str(len(preprocessed_papers)) + \" PAPERS\")\n",
    "print(\"--- EXAMPLE OF PREPROCESSED PAPER ---\")\n",
    "print(preprocessed_papers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292443ca",
   "metadata": {
    "papermill": {
     "duration": 0.008543,
     "end_time": "2025-04-12T22:22:41.332212",
     "exception": false,
     "start_time": "2025-04-12T22:22:41.323669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the preprocessed papers are transformed into vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b8d091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:22:41.351279Z",
     "iopub.status.busy": "2025-04-12T22:22:41.350891Z",
     "iopub.status.idle": "2025-04-12T22:24:08.015531Z",
     "shell.execute_reply": "2025-04-12T22:24:08.014148Z"
    },
    "papermill": {
     "duration": 86.688518,
     "end_time": "2025-04-12T22:24:08.029507",
     "exception": false,
     "start_time": "2025-04-12T22:22:41.340989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESSFULLY EMBEDDED 10000 PAPERS\n"
     ]
    }
   ],
   "source": [
    "def batch(iterable, n=100):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i + n]\n",
    "\n",
    "papers_embedded = []  \n",
    "papers_batches = list(batch(preprocessed_papers, 100)) #limit of 100 embeddings per call\n",
    "\n",
    "for batch in papers_batches:\n",
    "    batch_embedded = client.models.embed_content(\n",
    "        model='models/text-embedding-004',\n",
    "        contents=batch,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'))\n",
    "    list_batch_embedded = [e.values for e in batch_embedded.embeddings]\n",
    "    papers_embedded+=list_batch_embedded\n",
    "\n",
    "print(\"SUCCESSFULLY EMBEDDED \"+ str(len(papers_embedded)) + \" PAPERS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb776b1",
   "metadata": {
    "papermill": {
     "duration": 0.00812,
     "end_time": "2025-04-12T22:24:08.046308",
     "exception": false,
     "start_time": "2025-04-12T22:24:08.038188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Once the vector embeddings of the papers are computed, these are stored into the chromadb database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e41c03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:08.065253Z",
     "iopub.status.busy": "2025-04-12T22:24:08.064840Z",
     "iopub.status.idle": "2025-04-12T22:24:28.562778Z",
     "shell.execute_reply": "2025-04-12T22:24:28.561383Z"
    },
    "papermill": {
     "duration": 20.509915,
     "end_time": "2025-04-12T22:24:28.564763",
     "exception": false,
     "start_time": "2025-04-12T22:24:08.054848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESSFULLY UPLOADED 10000 PAPERS\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "def batch(iterable, batch_size):\n",
    "    for i in range(0, len(iterable), batch_size):\n",
    "        yield iterable[i:i + batch_size]\n",
    "\n",
    "\n",
    "# Start ChromaDB client\n",
    "chromadb_client = chromadb.Client()\n",
    "\n",
    "# Create or get a collection\n",
    "collection = chromadb_client.get_or_create_collection(name=\"papers\")\n",
    "\n",
    "# Add the documents + embeddings to Chroma\n",
    "emb_batches = list(batch(papers_embedded, 41000))\n",
    "papers_batches = list(batch(preprocessed_papers, 41000))\n",
    "for i in range(len(emb_batches)):\n",
    "    ids_batch = [f\"doc_{j + i * 41000}\" for j in range(len(emb_batches[i]))]\n",
    "    collection.add(\n",
    "        documents=papers_batches[i],\n",
    "        embeddings=emb_batches[i],\n",
    "        ids=ids_batch,\n",
    "    )\n",
    "print(\"SUCCESSFULLY UPLOADED \"+ str(len(papers_embedded)) + \" PAPERS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096bb5b",
   "metadata": {
    "papermill": {
     "duration": 0.008474,
     "end_time": "2025-04-12T22:24:28.582283",
     "exception": false,
     "start_time": "2025-04-12T22:24:28.573809",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vector database search example\n",
    "\n",
    "Now an example paper is used to search for similar papers in the database. If the same paper is obtained, the queried paper was in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44469d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:28.600928Z",
     "iopub.status.busy": "2025-04-12T22:24:28.600560Z",
     "iopub.status.idle": "2025-04-12T22:24:28.789214Z",
     "shell.execute_reply": "2025-04-12T22:24:28.788216Z"
    },
    "papermill": {
     "duration": 0.20035,
     "end_time": "2025-04-12T22:24:28.791044",
     "exception": false,
     "start_time": "2025-04-12T22:24:28.590694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_input = \"Statistical modeling of experimental physical laws is based on the probability density function of measured variables. It is expressed by experimental data via a kernel estimator. The kernel is determined objectively by the scattering of data during calibration of experimental setup. A physical law, which relates measured variables, is optimally extracted from experimental data by the conditional average estimator. It is derived directly from the kernel estimator and corresponds to a general nonparametric regression. T\"\n",
    "#query_input = pdf_text\n",
    "\n",
    "query_embedding = client.models.embed_content(\n",
    "        model='models/text-embedding-004',\n",
    "        contents=query_input,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0fd039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:28.810334Z",
     "iopub.status.busy": "2025-04-12T22:24:28.809986Z",
     "iopub.status.idle": "2025-04-12T22:24:28.824672Z",
     "shell.execute_reply": "2025-04-12T22:24:28.823302Z"
    },
    "papermill": {
     "duration": 0.026425,
     "end_time": "2025-04-12T22:24:28.826677",
     "exception": false,
     "start_time": "2025-04-12T22:24:28.800252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: doc_2287\n",
      "PAPER TITLE: Trapezoidal rule and sampling designs for the nonparametric estimation   of the regression function in models with correlated errors\n",
      "PAPER CONTENT:   The problem of estimating the regression function in a fixed design models with correlated observations is considered. Such observations are obtained from several experimental units, each of them forms a time series. Based on the trapezoidal rule, we propose a simple kernel estimator and we derive the asymptotic expression of its integrated mean squared error IMSE and its asymptotic normality. The problems of the optimal bandwidth and the optimal design with respect to the asymptotic IMSE are also investigated. Finally, a simulation study is conducted to study the performance of the new estimator and to compare it with the classical estimator of Gasser and M\\\"uller in a finite sample set. In addition, we study the robustness of the optimal design with respect to the misspecification of the autocovariance function. \n",
      "\n",
      "ID: doc_9559\n",
      "PAPER TITLE: Parameter estimation of ODE's via nonparametric estimators\n",
      "PAPER CONTENT:   Ordinary differential equations (ODE's) are widespread models in physics, chemistry and biology. In particular, this mathematical formalism is used for describing the evolution of complex systems and it might consist of high-dimensional sets of coupled nonlinear differential equations. In this setting, we propose a general method for estimating the parameters indexing ODE's from times series. Our method is able to alleviate the computational difficulties encountered by the classical parametric methods. These difficulties are due to the implicit definition of the model. We propose the use of a nonparametric estimator of regression functions as a first-step in the construction of an M-estimator, and we show the consistency of the derived estimator under general conditions. In the case of spline estimators, we prove asymptotic normality, and that the rate of convergence is the usual $\\sqrt{n}$-rate for parametric estimators. Some perspectives of refinements of this new family of parametric estimators are given. \n",
      "\n",
      "ID: doc_431\n",
      "PAPER TITLE: Born's rule from measurements of classical signals by threshold   detectors which are properly calibrated\n",
      "PAPER CONTENT:   The very old problem of the statistical content of quantum mechanics (QM) is studied in a novel framework. The Born's rule (one of the basic postulates of QM) is derived from theory of classical random signals. We present a measurement scheme which transforms continuous signals into discrete clicks and reproduces the Born's rule. This is the sheme of threshold type detection. Calibration of detectors plays a crucial role. \n",
      "\n",
      "ID: doc_4093\n",
      "PAPER TITLE: Higher Accuracy for Bayesian and Frequentist Inference: Large Sample   Theory for Small Sample Likelihood\n",
      "PAPER CONTENT:   Recent likelihood theory produces $p$-values that have remarkable accuracy and wide applicability. The calculations use familiar tools such as maximum likelihood values (MLEs), observed information and parameter rescaling. The usual evaluation of such $p$-values is by simulations, and such simulations do verify that the global distribution of the $p$-values is uniform(0, 1), to high accuracy in repeated sampling. The derivation of the $p$-values, however, asserts a stronger statement, that they have a uniform(0, 1) distribution conditionally, given identified precision information provided by the data. We take a simple regression example that involves exact precision information and use large sample techniques to extract highly accurate information as to the statistical position of the data point with respect to the parameter: specifically, we examine various $p$-values and Bayesian posterior survivor $s$-values for validity. With observed data we numerically evaluate the various $p$-values and $s$-values, and we also record the related general formulas. We then assess the numerical values for accuracy using Markov chain Monte Carlo (McMC) methods. We also propose some third-order likelihood-based procedures for obtaining means and variances of Bayesian posterior distributions, again followed by McMC assessment. Finally we propose some adaptive McMC methods to improve the simulation acceptance rates. All these methods are based on asymptotic analysis that derives from the effect of additional data. And the methods use simple calculations based on familiar maximizing values and related informations. The example illustrates the general formulas and the ease of calculations, while the McMC assessments demonstrate the numerical validity of the $p$-values as percentage position of a data point. The example, however, is very simple and transparent, and thus gives little indication that in a wide generality of models the formulas do accurately separate information for almost any parameter of interest, and then do give accurate $p$-value determinations from that information. As illustration an enigmatic problem in the literature is discussed and simulations are recorded; various examples in the literature are cited. \n",
      "\n",
      "ID: doc_7856\n",
      "PAPER TITLE: A binned likelihood for stochastic models\n",
      "PAPER CONTENT:   Metrics of model goodness-of-fit, model comparison, and model parameter estimation are the main categories of statistical problems in science. Bayesian and frequentist methods that address these questions often rely on a likelihood function, which is the key ingredient in order to assess the plausibility of model parameters given observed data. In some complex systems or experimental setups, predicting the outcome of a model cannot be done analytically, and Monte Carlo techniques are used. In this paper, we present a new analytic likelihood that takes into account Monte Carlo uncertainties, appropriate for use in the large and small sample size limits. Our formulation performs better than semi-analytic methods, prevents strong claims on biased statements, and provides improved coverage properties compared to available methods. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding.embeddings[0].values],\n",
    "    n_results=5  # Number of similar docs to return\n",
    ")\n",
    "\n",
    "for doc, doc_id in zip(results[\"documents\"][0], results[\"ids\"][0]):\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(f\"{doc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a852104",
   "metadata": {
    "papermill": {
     "duration": 0.008961,
     "end_time": "2025-04-12T22:24:28.844995",
     "exception": false,
     "start_time": "2025-04-12T22:24:28.836034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RETRIEVAL AUGMENTED GENERATION (RAG)\n",
    "For retrieval augmented generation, the question of the user together with the document are used to search for useful papers. With the useful papers and the user input, an answer is generated. The steps are as follow:\n",
    "1) Use a LLM to embed the user input question and input document for vector search.\n",
    "2) Obtain the original documents from the vector search in the database.\n",
    "3) Use the input question and input document and the original documents from the database to generate a response with a LLM.\n",
    "4) Show the answer to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848e175",
   "metadata": {
    "papermill": {
     "duration": 0.008417,
     "end_time": "2025-04-12T22:24:28.862263",
     "exception": false,
     "start_time": "2025-04-12T22:24:28.853846",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Orchestration functions\n",
    "The following functions orchestrate the RAG:\n",
    "\n",
    "- create_embedding(text): For a given text generates the corresponding vector embedding.\n",
    "- search_embedded_documents(query_embedding, n): For a given vector, searches nearby vectors in the vector embeddings database.\n",
    "- retrieve_documents(doc_id): For a given list of document ids, this function returns an extended information of each paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2f6a38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:28.880812Z",
     "iopub.status.busy": "2025-04-12T22:24:28.880407Z",
     "iopub.status.idle": "2025-04-12T22:24:28.887688Z",
     "shell.execute_reply": "2025-04-12T22:24:28.886472Z"
    },
    "papermill": {
     "duration": 0.018391,
     "end_time": "2025-04-12T22:24:28.889382",
     "exception": false,
     "start_time": "2025-04-12T22:24:28.870991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# === Tools ===\n",
    "def create_embedding(text)-> list:\n",
    "    print(f' - CALL: create_embedding({text[:20]})')\n",
    "    vector_embedding = client.models.embed_content(\n",
    "        model='models/text-embedding-004',\n",
    "        contents=text,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n",
    "    )\n",
    "    return vector_embedding.embeddings[0].values\n",
    "\n",
    "def search_embedded_documents(query_embedding:list[float], n:int)->list[str]:\n",
    "    print(f' - CALL: search_embedded_documents(n = {n})')\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def retrieve_documents(doc_ids:list[int])-> list[dict]:\n",
    "    print(f' - CALL: retrieve_documents(IDS = {doc_ids})')\n",
    "    papers_retrieved = []\n",
    "    for doc_id in doc_ids:\n",
    "        papers_retrieved.append(papers[doc_id])\n",
    "        \n",
    "    return papers_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8d7ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:28.908636Z",
     "iopub.status.busy": "2025-04-12T22:24:28.908296Z",
     "iopub.status.idle": "2025-04-12T22:24:29.441184Z",
     "shell.execute_reply": "2025-04-12T22:24:29.440016Z"
    },
    "papermill": {
     "duration": 0.544974,
     "end_time": "2025-04-12T22:24:29.443285",
     "exception": false,
     "start_time": "2025-04-12T22:24:28.898311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    text = \"\"\n",
    "    with pymupdf.open(path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"/kaggle/input/unc-paper/2409.10655v2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515e394f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:29.463504Z",
     "iopub.status.busy": "2025-04-12T22:24:29.463028Z",
     "iopub.status.idle": "2025-04-12T22:24:30.504022Z",
     "shell.execute_reply": "2025-04-12T22:24:30.502920Z"
    },
    "papermill": {
     "duration": 1.053701,
     "end_time": "2025-04-12T22:24:30.506044",
     "exception": false,
     "start_time": "2025-04-12T22:24:29.452343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_document = pdf_text[:1000]\n",
    "user_message = \"Find me related papers.\"\n",
    "\n",
    "instruction = \"\"\"\n",
    "You are a helpful chatbot that processes inputs from users and generates an output JSON for vector search. \n",
    "\n",
    "Given a user message and a document, return:\n",
    "{\n",
    "  \"embedding_query\": \"<summarized embedding query based on user message and document>\",\n",
    "  \"num_documents\": <integer number of documents to retrieve>\n",
    "}\n",
    "\n",
    "Ensure the output is a valid JSON object. 'embedding_query' should be a concise string that captures the main topic or keywords for semantic search. 'num_documents' should be inferred from the user message, defaulting to 5 if unspecified.\n",
    "\"\"\"\n",
    "\n",
    "contents = [\n",
    "    types.Content(\n",
    "        role=\"user\", parts=[types.Part(text=user_message),types.Part(text=pdf_text)]\n",
    "    )\n",
    "]\n",
    "\n",
    "response_init = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=instruction,\n",
    "        #tools=[orchestration_tools]\n",
    "    ),\n",
    "    contents = contents\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b93219",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:30.525593Z",
     "iopub.status.busy": "2025-04-12T22:24:30.525237Z",
     "iopub.status.idle": "2025-04-12T22:24:30.541283Z",
     "shell.execute_reply": "2025-04-12T22:24:30.540363Z"
    },
    "papermill": {
     "duration": 0.027809,
     "end_time": "2025-04-12T22:24:30.542748",
     "exception": false,
     "start_time": "2025-04-12T22:24:30.514939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "\n",
    "class RAG_Scientific_chatbot:\n",
    "        \n",
    "    def chat(self, question:str, document_path:str):\n",
    "               \n",
    "        processed_input, user_document = self._process_input(question, document_path)\n",
    "    \n",
    "        embedding = self._create_embedding(processed_input[\"embedding_query\"])\n",
    "        \n",
    "        search_output = self._search_embedded_documents(embedding, int(processed_input[\"num_documents\"]))\n",
    "        \n",
    "        doc_ids = search_output['ids'][0]  \n",
    "        numeric_ids = [int(doc.split('_')[1]) for doc in doc_ids]\n",
    "        extended_info = self._retrieve_documents(numeric_ids)\n",
    "        answer = self._generate_final_answer(question, user_document, search_output, extended_info)\n",
    "\n",
    "        return answer\n",
    "\n",
    "\n",
    "    # === Tools ===\n",
    "    def _process_input(self, user_message: str, document_path:str):\n",
    "        instruction = \"\"\"\n",
    "            You are a scientific research assistant specializing in analyzing academic papers and research questions.\n",
    "            \n",
    "            Your task is to analyze the user's question and their uploaded document to create:\n",
    "            1. An optimal embedding query for retrieving the most relevant scientific papers\n",
    "            2. A recommendation for how many papers to retrieve\n",
    "            \n",
    "            INSTRUCTIONS:\n",
    "            - Identify key scientific concepts, methodologies, domain-specific terminology, and research areas\n",
    "            - Extract specific technical terms that would appear in related papers\n",
    "            - Consider both the user's explicit question and the implicit research goals from their document\n",
    "            - Focus on scientific significance rather than general terms\n",
    "            - For empirical research questions, include methodology terms and measurement concepts\n",
    "            - For theoretical questions, include relevant frameworks and paradigms\n",
    "            \n",
    "            For number of documents:\n",
    "            - Suggest 3-5 papers for focused questions with specific methodology/technology\n",
    "            - Suggest 5-8 papers for broader research areas requiring multiple perspectives\n",
    "            - Suggest 8-12 papers for literature reviews or comparative analyses\n",
    "            \n",
    "            Return this string output:\n",
    "            \"{\"embedding_query\": \"<your optimized embedding query>\",\n",
    "             \"num_documents\": \"<number of papers to retrieve>\"}\"\n",
    "            \n",
    "            EXAMPLES:\n",
    "            Poor embedding query: \"machine learning effects\"\n",
    "            Good embedding query: \"transformer neural networks performance metrics BERT GPT comparative analysis NLP benchmarks\"\n",
    "            \"\"\"\n",
    "\n",
    "        pdf_text = self._extract_text_from_pdf(document_path)\n",
    "        \n",
    "        contents = [\n",
    "            types.Content(\n",
    "                role=\"user\", parts=[types.Part(text=user_message),types.Part(text=pdf_text)]\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        processed_input = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\", \n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=instruction,\n",
    "            ),\n",
    "            contents = contents\n",
    "        )\n",
    "        \n",
    "        match = re.search(r'\\{.*\\}', processed_input.text, re.DOTALL)\n",
    "        if match:\n",
    "            clean_json_str = match.group(0)\n",
    "            processed_input = json.loads(clean_json_str)\n",
    "     \n",
    "        return processed_input, pdf_text\n",
    "\n",
    "    \n",
    "    def _extract_text_from_pdf(self, path):\n",
    "        text = \"\"\n",
    "        with pymupdf.open(path) as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "        return text\n",
    "        \n",
    "        \n",
    "    def _create_embedding(self, text)-> list:\n",
    "        print(f' - CALL: create_embedding({text[:20]}...)')\n",
    "        vector_embedding = client.models.embed_content(\n",
    "            model='models/text-embedding-004',\n",
    "            contents=text,\n",
    "            config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n",
    "        )\n",
    "        return vector_embedding.embeddings[0].values\n",
    "    \n",
    "    def _search_embedded_documents(self, query_embedding:list[float], n:int)->list[str]:\n",
    "        print(f' - CALL: search_embedded_documents(n = {n})')\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=n\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def _retrieve_documents(self, doc_ids:list[int])-> list[dict]:\n",
    "        print(f' - CALL: retrieve_documents(IDS = {doc_ids})')\n",
    "        papers_retrieved = []\n",
    "        for doc_id in doc_ids:\n",
    "            papers_retrieved.append(papers[doc_id])\n",
    "            \n",
    "        return papers_retrieved\n",
    "        \n",
    "    def _generate_final_answer(self,question: str, user_document: str, search_output: str, extended_info: str):\n",
    "        instruction = \"\"\"\n",
    "            You are an advanced scientific research assistant tasked with providing comprehensive answers based on retrieved academic papers.\n",
    "            \n",
    "            CONTEXT:\n",
    "            - The user has asked a QUESTION about a scientific topic\n",
    "            - They've provided their own INPUT_DOCUMENT (a scientific paper or research proposal)\n",
    "            - You've retrieved relevant papers from a scientific database (EMBED_DATA and EXTENDED_PAPER_INFO)\n",
    "            \n",
    "            YOUR TASK:\n",
    "            1. Analyze the retrieved papers and determine their relevance to the question\n",
    "            2. Provide an answer based on the retreived papers from EMBED_DATA and EXTENDED_PAPER_INFO. \n",
    "            3. You may use information from the INPUT_DOCUMENT if the papers from EMBED_DATA and EXTENDED_PAPER_INFO are not relevant. Always mention where the information is obtained from.\n",
    "            \n",
    "            IMPORTANT GUIDELINES:\n",
    "            - SKIP the user's own paper if it appears in the results\n",
    "            - Prioritize recent papers and high-impact findings\n",
    "            - Compare and contrast contradictory findings when present\n",
    "            - Always provide authors and publication dates\n",
    "            - Focus on scientific significance rather than general summaries\n",
    "            - For methodology questions, emphasize technical details and implementation\n",
    "            - Use objective, academically-appropriate language\n",
    "            - Provide the answer in a Markdown format\n",
    "            - You do not need to show all the papers from EMBED_DATA and EXTENDED_PAPER_INFO, only the most relevant and important\n",
    "            - For the answer, use only papers from the database. You may include some suggestions to other papers but don't make it too extensive.\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "        prompt =f\"\"\"\n",
    "                QUESTION:{user_message}\n",
    "                INPUT_DOCUMENT:{user_document}\n",
    "                EMBED_DATA: {search_output}\n",
    "                EXTENDED_PAPER_INFO: {extended_info}\n",
    "                \"\"\"\n",
    "        \n",
    "        contents = []\n",
    "        contents.append(types.Content(role=\"user\", parts=[types.Part(text = prompt)]))\n",
    "        response_final = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\", \n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=instruction\n",
    "            ),\n",
    "            contents = contents\n",
    "        )\n",
    "        return response_final.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79b271f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:30.561475Z",
     "iopub.status.busy": "2025-04-12T22:24:30.561122Z",
     "iopub.status.idle": "2025-04-12T22:24:35.408917Z",
     "shell.execute_reply": "2025-04-12T22:24:35.407834Z"
    },
    "papermill": {
     "duration": 4.859059,
     "end_time": "2025-04-12T22:24:35.410617",
     "exception": false,
     "start_time": "2025-04-12T22:24:30.551558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - CALL: create_embedding(deep reinforcement l...)\n",
      " - CALL: search_embedded_documents(n = 7)\n",
      " - CALL: retrieve_documents(IDS = [4064, 3257, 6329, 5726, 4074, 5484, 9038])\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "Here are some papers that focus on uncertainty estimation in the context of robot navigation and reinforcement learning.\n",
       "\n",
       "*   **LEADER: Learning Attention over Driving Behaviors for Planning under Uncertainty (Danesh et al., 2022)**\n",
       "\n",
       "    *   Addresses challenges in autonomous driving caused by uncertainty in human behaviors.\n",
       "    *   Introduces a method called LEarning Attention over Driving bEhavioRs (LEADER) that uses a neural network to focus on critical human behaviors during planning.\n",
       "    *   LEADER integrates attention into a belief-space planner, using importance sampling to bias reasoning towards critical events and learns risk-aware planning without human labeling by formulating a min-max game between the attention generator and the planner.\n",
       "\n",
       "*   **Decentralized Multi-Robot Navigation for Autonomous Surface Vehicles with Distributional Reinforcement Learning (Lin et al., 2024)**\n",
       "\n",
       "    *   Proposes a decentralized multi-ASV collision avoidance policy using Distributional Reinforcement Learning, which accounts for interactions among ASVs, static obstacles, and current flows.\n",
       "    *   A variant of the framework automatically adapts its risk sensitivity to improve ASV safety in congested environments.\n",
       "    \n",
       "*   **n-MeRCI: A new Metric to Evaluate the Correlation Between Predictive Uncertainty and True Error (Moukari et al., 2019)**\n",
       "\n",
       "    *   Proposes a novel metric for evaluating relative uncertainty assessment, applicable to regression with deep neural networks.\n",
       "    *   The metric is designed to assess the quality of estimated uncertainty, which is important in robotics where actions depend on the confidence in perceived information.\n",
       "\n",
       "*   **Safe Reinforcement Learning using Data-Driven Predictive Control (Selim et al., 2022)**\n",
       "\n",
       "    *   Introduces a data-driven safety layer that filters unsafe actions in reinforcement learning.\n",
       "    *   The safety layer uses a data-driven predictive controller to enforce safety guarantees for RL policies during training and deployment, using reachability analysis to verify proposed actions.\n",
       "\n",
       "*   **Robust Constrained-MDPs: Soft-Constrained Robust Policy Optimization under Model Uncertainty (Russel et al., 2020)**\n",
       "\n",
       "    *   Focuses on making reinforcement learning algorithms more robust to model uncertainties.\n",
       "    *   Merges constrained Markov decision processes (CMDP) with robust Markov decision processes (RMDP), leading to a formulation of robust constrained-MDPs (RCMDP).\n",
       "    *   The formulation provides constraint satisfaction guarantees with respect to uncertainties in the system's state transition probabilities.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "\n",
    "document = \"/kaggle/input/unc-paper/2409.10655v2.pdf\"\n",
    "user_message = \"Find me related papers with emphasis in uncertainty estimation.\"\n",
    "\n",
    "chatbot = RAG_Scientific_chatbot()\n",
    "answer = chatbot.chat(user_message, document)\n",
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bd18b3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:35.430031Z",
     "iopub.status.busy": "2025-04-12T22:24:35.429610Z",
     "iopub.status.idle": "2025-04-12T22:24:35.436062Z",
     "shell.execute_reply": "2025-04-12T22:24:35.435093Z"
    },
    "papermill": {
     "duration": 0.017856,
     "end_time": "2025-04-12T22:24:35.437627",
     "exception": false,
     "start_time": "2025-04-12T22:24:35.419771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```markdown\n",
       "Here are some papers that focus on uncertainty estimation in the context of robot navigation and reinforcement learning.\n",
       "\n",
       "*   **LEADER: Learning Attention over Driving Behaviors for Planning under Uncertainty (Danesh et al., 2022)**\n",
       "\n",
       "    *   Addresses challenges in autonomous driving caused by uncertainty in human behaviors.\n",
       "    *   Introduces a method called LEarning Attention over Driving bEhavioRs (LEADER) that uses a neural network to focus on critical human behaviors during planning.\n",
       "    *   LEADER integrates attention into a belief-space planner, using importance sampling to bias reasoning towards critical events and learns risk-aware planning without human labeling by formulating a min-max game between the attention generator and the planner.\n",
       "\n",
       "*   **Decentralized Multi-Robot Navigation for Autonomous Surface Vehicles with Distributional Reinforcement Learning (Lin et al., 2024)**\n",
       "\n",
       "    *   Proposes a decentralized multi-ASV collision avoidance policy using Distributional Reinforcement Learning, which accounts for interactions among ASVs, static obstacles, and current flows.\n",
       "    *   A variant of the framework automatically adapts its risk sensitivity to improve ASV safety in congested environments.\n",
       "    \n",
       "*   **n-MeRCI: A new Metric to Evaluate the Correlation Between Predictive Uncertainty and True Error (Moukari et al., 2019)**\n",
       "\n",
       "    *   Proposes a novel metric for evaluating relative uncertainty assessment, applicable to regression with deep neural networks.\n",
       "    *   The metric is designed to assess the quality of estimated uncertainty, which is important in robotics where actions depend on the confidence in perceived information.\n",
       "\n",
       "*   **Safe Reinforcement Learning using Data-Driven Predictive Control (Selim et al., 2022)**\n",
       "\n",
       "    *   Introduces a data-driven safety layer that filters unsafe actions in reinforcement learning.\n",
       "    *   The safety layer uses a data-driven predictive controller to enforce safety guarantees for RL policies during training and deployment, using reachability analysis to verify proposed actions.\n",
       "\n",
       "*   **Robust Constrained-MDPs: Soft-Constrained Robust Policy Optimization under Model Uncertainty (Russel et al., 2020)**\n",
       "\n",
       "    *   Focuses on making reinforcement learning algorithms more robust to model uncertainties.\n",
       "    *   Merges constrained Markov decision processes (CMDP) with robust Markov decision processes (RMDP), leading to a formulation of robust constrained-MDPs (RCMDP).\n",
       "    *   The formulation provides constraint satisfaction guarantees with respect to uncertainties in the system's state transition probabilities.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if answer and isinstance(answer, str):\n",
    "    display(Markdown(answer))\n",
    "else:\n",
    "    print(\"Received non-string response:\", type(answer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d511af46",
   "metadata": {
    "papermill": {
     "duration": 0.009403,
     "end_time": "2025-04-12T22:24:35.456760",
     "exception": false,
     "start_time": "2025-04-12T22:24:35.447357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Appendix: Partial code for an AI Agent \n",
    "\n",
    "This code is provided for future improvement, given that the code did not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2afb57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:35.476026Z",
     "iopub.status.busy": "2025-04-12T22:24:35.475637Z",
     "iopub.status.idle": "2025-04-12T22:24:35.481549Z",
     "shell.execute_reply": "2025-04-12T22:24:35.480644Z"
    },
    "papermill": {
     "duration": 0.0173,
     "end_time": "2025-04-12T22:24:35.483180",
     "exception": false,
     "start_time": "2025-04-12T22:24:35.465880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Tool declarations ===\n",
    "create_embedding_tool = {\n",
    "    \"name\" : \"create_embedding\",\n",
    "    \"description\" : \"For a given text, generate the corresponding vector embedding.\",\n",
    "    \"parameters\" : {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"STRING\",\n",
    "                \"description\": \"The input text to embed.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"text\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "search_embedded_documents_tool = {\n",
    "    \"name\" : \"search_embedded_documents\",\n",
    "    \"description\" : \"Search for similar documents using a query embedding.\",\n",
    "    \"parameters\" : {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"query_embedding\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"NUMBER\"  # O \"INTEGER\" si tus vectores son int (normalmente son floats)\n",
    "                },\n",
    "                \"description\": \"The vector embedding of the input query.\"\n",
    "            },\n",
    "            \"n\": {\n",
    "                \"type\": \"INTEGER\",\n",
    "                \"description\": \"Number of top similar documents to retrieve.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query_embedding\", \"n\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "retrieve_documents_tool = {\n",
    "    \"name\" : \"retrieve_documents\",\n",
    "    \"description\" : \"Retrieve detailed information about a document using its ID.\",\n",
    "    \"parameters\" : {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"doc_id\": {\n",
    "                \"type\": \"INTEGER\",\n",
    "                \"description\": \"The ID of the paper/document.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"doc_id\"]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e38d5e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:35.503040Z",
     "iopub.status.busy": "2025-04-12T22:24:35.502633Z",
     "iopub.status.idle": "2025-04-12T22:24:35.508024Z",
     "shell.execute_reply": "2025-04-12T22:24:35.506781Z"
    },
    "papermill": {
     "duration": 0.017374,
     "end_time": "2025-04-12T22:24:35.510031",
     "exception": false,
     "start_time": "2025-04-12T22:24:35.492657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#orchestration_tools  = types.Tool(function_declarations=[create_embedding_tool, search_embedded_documents_tool])\n",
    "\n",
    "orchestration_tools  = types.Tool(function_declarations=[create_embedding_tool, search_embedded_documents_tool])\n",
    "\n",
    "\n",
    "instruction = \"\"\"You are a helpful chatbot that can interact with a database of vector embeddings\n",
    "of scientific papers and a database with the papers extended information. You will take the users questions and documents andgenerate\n",
    "\n",
    "Use the following tools:\n",
    "    - create_embedding(text) to convert text into vector embeddings \n",
    "    - search_embedded_documents(query_embedding, n) to obtain n papers that are similar to the embedded query \n",
    "from the database of vector embeddings.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91aa4eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T22:24:35.530230Z",
     "iopub.status.busy": "2025-04-12T22:24:35.529879Z",
     "iopub.status.idle": "2025-04-12T22:24:35.534060Z",
     "shell.execute_reply": "2025-04-12T22:24:35.533100Z"
    },
    "papermill": {
     "duration": 0.016074,
     "end_time": "2025-04-12T22:24:35.535609",
     "exception": false,
     "start_time": "2025-04-12T22:24:35.519535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tool_call = response.candidates[0].content.parts[0].function_call\n",
    "\n",
    "#if tool_call.name == \"create_embedding\":\n",
    "#    result = create_embedding(**tool_call.args)\n",
    "\n",
    "#function_response_part = types.Part.from_function_response(\n",
    "#    name=tool_call.name,\n",
    "#    response={\"result\": result},\n",
    "#)\n",
    "\n",
    "#contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=tool_call)])) # Append the model's function call message\n",
    "#contents.append(types.Content(role=\"user\", parts=[function_response_part])) # Append the function response\n",
    "#response = client.models.generate_content(\n",
    "#    model=\"gemini-2.0-flash\", \n",
    "#    config=types.GenerateContentConfig(\n",
    "#        system_instruction=instruction,\n",
    "#        tools=[orchestration_tools]\n",
    "#    ),\n",
    "#    contents = contents\n",
    "#)\n",
    "#print(response)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 612177,
     "sourceId": 11291024,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7088951,
     "sourceId": 11332325,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 329.794351,
   "end_time": "2025-04-12T22:24:38.769469",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-12T22:19:08.975118",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
