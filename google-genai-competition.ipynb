{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":11382540,"datasetId":612177,"databundleVersionId":11814972},{"sourceType":"datasetVersion","sourceId":11332325,"datasetId":7088951,"databundleVersionId":11757919}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Scientific Paper Recommendation System with RAG\n## Project Description\nThis project implements a Retrieval Augmented Generation (RAG) system for scientific paper recommendations. The system allows users to input a document or query and receive recommendations for relevant scientific papers from the ArXiv database.\n\n## Key Components\nVector Database: Uses a ChromaDB vector database containing embeddings of 10,000 ArXiv research papers\nDocument Processing: Extracts and processes PDF content using PyMuPDF\nSemantic Search: Performs similarity searches based on document content\n\n## GenAI Functionalities\n- Embeddings: Generates semantic embeddings using Google's text-embedding-004 model\n- Prompt Engineering: Utilizes carefully crafted prompts to guide the AI's behavior\n- RAG Implementation: Combines vector search results with generative AI responses\n- Document Understanding: Processes and interprets PDF research papers\n- Vector Embedding and Vector Search: Performs semantic similarity searches in high-dimensional vector space\n\nThe system orchestrates these components through a chatbot interface that processes user queries, searches for relevant papers, and generates comprehensive responses that include paper details like authors and publication dates.\n\n## Database\nArXiv serves as an excellent data source for our recommendation system for several key reasons:\n\n- **Rich Scientific Content**: Contains over 2 million scholarly articles across multiple disciplines\n- **Well-Structured Metadata**: Includes titles, abstracts, authors, and categories in a consistent format\n- **Embedding-Friendly**: Abstracts provide concise, information-dense text that produces meaningful vector embeddings\n- **Research Relevance**: Widely used by the scientific community, ensuring practical utility\n- **Semantic Search Compatibility**: Content structure works effectively with our embedding model (text-embedding-004)\n\nOur implementation uses 10,000 ArXiv papers converted to vector embeddings and stored in ChromaDB, enabling semantic similarity searches to retrieve relevant scientific literature for user queries. The Arxiv dataset is available in Kagggle with the following link: [Arxiv_dataset](https://www.kaggle.com/datasets/Cornell-University/arxiv). \n## Use Case\nResearchers can upload a scientific paper and ask questions to find related work in the ArXiv database, facilitating literature reviews and discovery of relevant research.\n\n````\nchatbot = RAG_Scientific_chatbot()\nanswer = chatbot.chat(\"Find me related papers\", \"/path/to/document.pdf\")\ndisplay(Markdown(answer))\n```` \n","metadata":{}},{"cell_type":"markdown","source":"## Setup\nImport and install the necessary libraries.","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n!pip install --upgrade pymupdf\n\nfrom google import genai\nfrom google.genai import types\n\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T18:58:12.653444Z","iopub.execute_input":"2025-04-13T18:58:12.653831Z","iopub.status.idle":"2025-04-13T18:59:00.493693Z","shell.execute_reply.started":"2025-04-13T18:58:12.653790Z","shell.execute_reply":"2025-04-13T18:59:00.492656Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\ngoogle-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\ntensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mCollecting pymupdf\n  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.25.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# API keys\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T18:59:00.495098Z","iopub.execute_input":"2025-04-13T18:59:00.495669Z","iopub.status.idle":"2025-04-13T18:59:00.913849Z","shell.execute_reply.started":"2025-04-13T18:59:00.495633Z","shell.execute_reply":"2025-04-13T18:59:00.912867Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Define a retry policy. The model might make multiple consecutive calls automatically\n# for a complex query, this ensures the client retries if it hits quota limits.\nfrom google.api_core import retry\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T18:59:00.915946Z","iopub.execute_input":"2025-04-13T18:59:00.916319Z","iopub.status.idle":"2025-04-13T18:59:01.158119Z","shell.execute_reply.started":"2025-04-13T18:59:00.916283Z","shell.execute_reply":"2025-04-13T18:59:01.156731Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Upload of Arxiv papers\nFirst the arxiv dataset is imported and a vector embedding of all the documents is perfomed. After the vector embedding,these are stored in a chromadb vector database. The arxiv dataset import is shown below. Given that it is computationally expensive to import and process all papers, only a few are imported randomly.","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\namount_papers = 10000\npapers = []\n\nwith open('/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json', 'r') as file:\n    for i, line in enumerate(file):\n        papers.append(json.loads(line))\n\nrandom_indices = set(random.sample(range(len(papers)), amount_papers))\nrandom_indices = list(random_indices)\npapers_random = []\nfor i in range(len(random_indices)):\n    index = random_indices[i]\n    papers_random.append(papers[index])\npapers = papers_random\n# Now data is a list of dictionaries\nprint(\"Headers:\", list(papers[0].keys()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T18:59:01.159942Z","iopub.execute_input":"2025-04-13T18:59:01.160558Z","iopub.status.idle":"2025-04-13T19:01:07.290155Z","shell.execute_reply.started":"2025-04-13T18:59:01.160515Z","shell.execute_reply":"2025-04-13T19:01:07.288789Z"}},"outputs":[{"name":"stdout","text":"Headers: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Only the title and the abstract of each paper are embedded. The code below implements this preprocessing of the papers.","metadata":{}},{"cell_type":"code","source":"def remove_newlines(obj):\n    if isinstance(obj, str):\n        return obj.replace('\\n', ' ')\n        \npreprocessed_papers = []\nfor paper in papers:\n    preprocessed_papers.append(\"PAPER TITLE: \" + remove_newlines(paper[\"title\"]) + \"\\nPAPER CONTENT: \"+ remove_newlines(paper[\"abstract\"]))\nprint(\"SUCCESSFULLY PREPROCESSED \"+ str(len(preprocessed_papers)) + \" PAPERS\")\nprint(\"--- EXAMPLE OF PREPROCESSED PAPER ---\")\nprint(preprocessed_papers[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:01:07.395521Z","iopub.execute_input":"2025-04-13T19:01:07.395984Z","iopub.status.idle":"2025-04-13T19:01:07.843572Z","shell.execute_reply.started":"2025-04-13T19:01:07.395950Z","shell.execute_reply":"2025-04-13T19:01:07.842315Z"}},"outputs":[{"name":"stdout","text":"SUCCESSFULLY PREPROCESSED 10000 PAPERS\n--- EXAMPLE OF PREPROCESSED PAPER ---\nPAPER TITLE: Harmonic forcing of an extended oscillatory system: Homogeneous and   periodic solutions\nPAPER CONTENT:   In this paper we study the effect of external harmonic forcing on a one-dimensional oscillatory system described by the complex Ginzburg-Landau equation (CGLE). For a sufficiently large forcing amplitude, a homogeneous state with no spatial structure is observed. The state becomes unstable to a spatially periodic ``stripe'' state via a supercritical bifurcation as the forcing amplitude decreases. An approximate phase equation is derived, and an analytic solution for the stripe state is obtained, through which the asymmetric behavior of the stability border of the state is explained. The phase equation, in particular the analytic solution, is found to be very useful in understanding the stability borders of the homogeneous and stripe states of the forced CGLE. \n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Now the preprocessed papers are transformed into vector embeddings with the embedding model  models/text-embedding-004.","metadata":{}},{"cell_type":"code","source":"def batch(iterable, n=100):\n    for i in range(0, len(iterable), n):\n        yield iterable[i:i + n]\n\npapers_embedded = []  \npapers_batches = list(batch(preprocessed_papers, 100)) #limit of 100 embeddings per call\n\nfor batch in papers_batches:\n    batch_embedded = client.models.embed_content(\n        model='models/text-embedding-004',\n        contents=batch,\n        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'))\n    list_batch_embedded = [e.values for e in batch_embedded.embeddings]\n    papers_embedded+=list_batch_embedded\n\nprint(\"SUCCESSFULLY EMBEDDED \"+ str(len(papers_embedded)) + \" PAPERS\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:01:07.844882Z","iopub.execute_input":"2025-04-13T19:01:07.845541Z","iopub.status.idle":"2025-04-13T19:02:31.242714Z","shell.execute_reply.started":"2025-04-13T19:01:07.845495Z","shell.execute_reply":"2025-04-13T19:02:31.241137Z"}},"outputs":[{"name":"stdout","text":"SUCCESSFULLY EMBEDDED 10000 PAPERS\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Once the vector embeddings of the papers are computed, these are stored into the chromadb database.","metadata":{}},{"cell_type":"code","source":"import chromadb\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\ndef batch(iterable, batch_size):\n    for i in range(0, len(iterable), batch_size):\n        yield iterable[i:i + batch_size]\n\n\n# Start ChromaDB client\nchromadb_client = chromadb.Client()\n\n# Create or get a collection\ncollection = chromadb_client.get_or_create_collection(name=\"papers\")\n\n# Add the documents + embeddings to Chroma\nemb_batches = list(batch(papers_embedded, 41000))\npapers_batches = list(batch(preprocessed_papers, 41000))\nfor i in range(len(emb_batches)):\n    ids_batch = [f\"doc_{j + i * 41000}\" for j in range(len(emb_batches[i]))]\n    collection.add(\n        documents=papers_batches[i],\n        embeddings=emb_batches[i],\n        ids=ids_batch,\n    )\nprint(\"SUCCESSFULLY UPLOADED \"+ str(len(papers_embedded)) + \" PAPERS\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:02:31.244376Z","iopub.execute_input":"2025-04-13T19:02:31.244738Z","iopub.status.idle":"2025-04-13T19:02:51.508991Z","shell.execute_reply.started":"2025-04-13T19:02:31.244690Z","shell.execute_reply":"2025-04-13T19:02:51.507971Z"}},"outputs":[{"name":"stdout","text":"SUCCESSFULLY UPLOADED 10000 PAPERS\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Vector database search example\n\nNow an extract of a sample paper is used to search for similar papers in the database. If the same paper is obtained, the queried paper was in the database.","metadata":{}},{"cell_type":"code","source":"query_input = \"Statistical modeling of experimental physical laws is based on the probability density function of measured variables. It is expressed by experimental data via a kernel estimator. The kernel is determined objectively by the scattering of data during calibration of experimental setup. A physical law, which relates measured variables, is optimally extracted from experimental data by the conditional average estimator. It is derived directly from the kernel estimator and corresponds to a general nonparametric regression. T\"\n#query_input = pdf_text\n\nquery_embedding = client.models.embed_content(\n        model='models/text-embedding-004',\n        contents=query_input,\n        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:02:51.512156Z","iopub.execute_input":"2025-04-13T19:02:51.512455Z","iopub.status.idle":"2025-04-13T19:02:51.883189Z","shell.execute_reply.started":"2025-04-13T19:02:51.512428Z","shell.execute_reply":"2025-04-13T19:02:51.882305Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"results = collection.query(\n    query_embeddings=[query_embedding.embeddings[0].values],\n    n_results=5  # Number of similar docs to return\n)\n\nfor doc, doc_id in zip(results[\"documents\"][0], results[\"ids\"][0]):\n    print(f\"ID: {doc_id}\")\n    print(f\"{doc}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:02:51.884657Z","iopub.execute_input":"2025-04-13T19:02:51.884951Z","iopub.status.idle":"2025-04-13T19:02:51.900374Z","shell.execute_reply.started":"2025-04-13T19:02:51.884927Z","shell.execute_reply":"2025-04-13T19:02:51.899293Z"}},"outputs":[{"name":"stdout","text":"ID: doc_6323\nPAPER TITLE: Machine learning memory kernels as closure for non-Markovian stochastic   processes\nPAPER CONTENT:   Finding the dynamical law of observable quantities lies at the core of physics. Within the particular field of statistical mechanics, the generalized Langevin equation (GLE) comprises a general model for the evolution of observables covering a great deal of physical systems with many degrees of freedom and an inherently stochastic nature. Although formally exact, the GLE brings its own great challenges. It depends on the complete history of the observables under scrutiny, as well as the microscopic degrees of freedom, all of which are often inaccessible. We show that these drawbacks can be overcome by adopting elements of machine learning from empirical data, in particular coupling a multilayer perceptron (MLP) with the formal structure of the GLE and calibrating the MLP with the data. This yields a powerful computational tool capable of describing noisy complex systems beyond the realms of statistical mechanics. It is exemplified with a number of representative examples from different fields: from a single colloidal particle and particle chains in a thermal bath to climatology and finance, showing in all cases excellent agreement with the actual observable dynamics. The new framework offers an alternative perspective for the study of non-equilibrium processes opening also a new route for stochastic modelling. \n\nID: doc_6941\nPAPER TITLE: The nature of mathematical models\nPAPER CONTENT:   Modeling has become a widespread, useful tool in mathematics applied to diverse fields, from physics to economics to biomedicine. Practitioners of modeling may use algebraic or differential equations, to the elements of which they attribute an intuitive relationship with some relevant aspect of reality they wish to represent. More sophisticated expressions may include stochasticity, either as observation error or system noise. However, a clear, unambiguous mathematical definition of what a model is and of what is the relationship between the model and the real-life phenomena it purports to represent has so far not been formulated. The present work aims to fill this gap, motivating the definition of a mathematical model as an operator on a Hilbert space of random variables, identifying the experimental realization as the map between the theoretical space of model construction and the computational space of statistical model identification, and tracing the relationship of the geometry of the model manifold in the abstract setting with the corresponding geometry of the prediction surfaces in statistical estimation. \n\nID: doc_7059\nPAPER TITLE: Characterizing predictable classes of processes\nPAPER CONTENT:   The problem is sequence prediction in the following setting. A sequence x1,..., xn,... of discrete-valued observations is generated according to some unknown probabilistic law (measure) mu. After observing each outcome, it is required to give the conditional probabilities of the next observation. The measure mu belongs to an arbitrary class C of stochastic processes. We are interested in predictors ? whose conditional probabilities converge to the 'true' mu-conditional probabilities if any mu { C is chosen to generate the data. We show that if such a predictor exists, then a predictor can also be obtained as a convex combination of a countably many elements of C. In other words, it can be obtained as a Bayesian predictor whose prior is concentrated on a countable set. This result is established for two very different measures of performance of prediction, one of which is very strong, namely, total variation, and the other is very weak, namely, prediction in expected average Kullback-Leibler divergence. \n\nID: doc_9690\nPAPER TITLE: On the conditional distributions of low-dimensional projections from   high-dimensional data\nPAPER CONTENT:   We study the conditional distribution of low-dimensional projections from high-dimensional data, where the conditioning is on other low-dimensional projections. To fix ideas, consider a random d-vector Z that has a Lebesgue density and that is standardized so that $\\mathbb{E}Z=0$ and $\\mathbb{E}ZZ'=I_d$. Moreover, consider two projections defined by unit-vectors $\\alpha$ and $\\beta$, namely a response $y=\\alpha'Z$ and an explanatory variable $x=\\beta'Z$. It has long been known that the conditional mean of y given x is approximately linear in x$ under some regularity conditions; cf. Hall and Li [Ann. Statist. 21 (1993) 867-889]. However, a corresponding result for the conditional variance has not been available so far. We here show that the conditional variance of y given x is approximately constant in x (again, under some regularity conditions). These results hold uniformly in $\\alpha$ and for most $\\beta$'s, provided only that the dimension of Z is large. In that sense, we see that most linear submodels of a high-dimensional overall model are approximately correct. Our findings provide new insights in a variety of modeling scenarios. We discuss several examples, including sliced inverse regression, sliced average variance estimation, generalized linear models under potential link violation, and sparse linear modeling. \n\nID: doc_234\nPAPER TITLE: Bayesian Estimation of Experimental Parameters in Stochastic Inertial   Systems: Theory, Simulations, and Experiments with Objects Levitated in   Vacuum\nPAPER CONTENT:   High-quality nanomechanical oscillators can sensitively probe force, mass, or displacement in experiments bridging the gap between the classical and quantum domain. Dynamics of these stochastic systems is inherently determined by the interplay between acting external forces, viscous dissipation, and random driving by the thermal environment. The importance of inertia then dictates that both position and momentum must, in principle, be known to fully describe the system, which makes its quantitative experimental characterization rather challenging. We introduce a general method of Bayesian inference of the force field and environmental parameters in stochastic inertial systems that operates solely on the time series of recorded noisy positions of the system. The method is first validated on simulated trajectories of model stochastic harmonic and anharmonic oscillators with damping. Subsequently, the method is applied to experimental trajectories of particles levitating in tailored optical fields and used to characterize the dynamics of particle motion in a nonlinear Duffing potential, a static or time-dependent double-well potential, and a non-conservative force field. The presented inference procedure does not make any simplifying assumptions about the nature or symmetry of the acting force field and provides robust results with trajectories two orders of magnitude shorter than those typically required by alternative inference schemes. In addition to being a powerful tool for quantitative data analysis, it can also guide experimentalists in choosing appropriate sampling frequency (at least 20 measured points per single characteristic period) and length of the measured trajectories (at least 10 periods) to estimate the force field and environmental characteristics with a desired accuracy and precision. \n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## RETRIEVAL AUGMENTED GENERATION (RAG)\nFor retrieval augmented generation, the question of the user together with the document are used to search for useful papers. With the useful papers and the user input, an answer is generated. The steps are as follow:\n1) Use a LLM to embed the user input question and input document for vector search.\n2) Obtain the original documents from the vector search in the database.\n3) Use the input question and input document and the original documents from the database to generate a response with a LLM.\n4) Show the answer to the user.\n\nPrompt engineering is employed to adjust the answers of the chatbot.","metadata":{}},{"cell_type":"markdown","source":"### Orchestration functions\nThe following functions orchestrate the RAG and found in the class RAG_Scientific_chatbot:\n\n- _create_embedding(text): For a given text generates the corresponding vector embedding.\n- _search_embedded_documents(query_embedding, n): For a given vector, searches nearby vectors in the vector embeddings database.\n- _retrieve_documents(doc_id): For a given list of document ids, this function returns an extended information of each paper.","metadata":{}},{"cell_type":"code","source":"import pymupdf\nimport re\n\nclass RAG_Scientific_chatbot:\n        \n    def chat(self, question:str, document_path:str=None):\n                           \n        processed_input, user_document = self._process_input(question, document_path)\n    \n        embedding = self._create_embedding(processed_input[\"embedding_query\"])\n        \n        search_output = self._search_embedded_documents(embedding, int(processed_input[\"num_documents\"]))\n        \n        doc_ids = search_output['ids'][0]  \n        numeric_ids = [int(doc.split('_')[1]) for doc in doc_ids]\n        extended_info = self._retrieve_documents(numeric_ids)\n        answer = self._generate_final_answer(question, user_document, search_output, extended_info)\n\n        return answer\n\n\n    # === Tools ===\n    def _process_input(self, user_message: str, document_path:str = None ):\n        instruction = \"\"\"\n            You are a scientific research assistant specializing in analyzing academic papers and research questions.\n            \n            Your task is to analyze the user's question and their uploaded document to create:\n            1. An optimal embedding query for retrieving the most relevant scientific papers\n            2. A recommendation for how many papers to retrieve\n            \n            INSTRUCTIONS:\n            - Identify key scientific concepts, methodologies, domain-specific terminology, and research areas\n            - Extract specific technical terms that would appear in related papers\n            - Consider both the user's explicit question and the implicit research goals from their document\n            - Focus on scientific significance rather than general terms\n            - For empirical research questions, include methodology terms and measurement concepts\n            - For theoretical questions, include relevant frameworks and paradigms\n            \n            For number of documents:\n            - Suggest 3-5 papers for focused questions with specific methodology/technology\n            - Suggest 5-8 papers for broader research areas requiring multiple perspectives\n            - Suggest 8-12 papers for literature reviews or comparative analyses\n            - If the amount of papers is explicit in QUESTION, search for this amount of papers or more\n            \n            \n            Return this string output:\n            \"{\"embedding_query\": \"<your optimized embedding query>\",\n             \"num_documents\": \"<number of papers to retrieve>\"}\"\n            \n            EXAMPLES:\n            \n            Question: Find me 3 papers about science and 2 about nature.  \n            Good num_documents: 7\n            Bad num_documents: 3\n            \n            \"\"\"\n\n        if document_path != None:\n            pdf_text = self._extract_text_from_pdf(document_path)\n            contents = [\n                types.Content(\n                    role=\"user\", parts=[types.Part(text=user_message),types.Part(text=pdf_text)]\n                )\n            ]\n          \n        else: \n            pdf_text = None\n            contents = [\n                types.Content(\n                    role=\"user\", parts=[types.Part(text=user_message)]\n                )\n            ]\n        \n        \n        processed_input = client.models.generate_content(\n            model=\"gemini-2.0-flash\", \n            config=types.GenerateContentConfig(\n                system_instruction=instruction,\n            ),\n            contents = contents\n        )\n        \n        match = re.search(r'\\{.*\\}', processed_input.text, re.DOTALL)\n        if match:\n            clean_json_str = match.group(0)\n            processed_input = json.loads(clean_json_str)\n     \n        return processed_input, pdf_text\n\n    \n    def _extract_text_from_pdf(self, path):\n        text = \"\"\n        with pymupdf.open(path) as doc:\n            for page in doc:\n                text += page.get_text()\n        return text\n        \n        \n    def _create_embedding(self, text)-> list:\n        print(f' - CALL: create_embedding({text[:20]}...)')\n        vector_embedding = client.models.embed_content(\n            model='models/text-embedding-004',\n            contents=text,\n            config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n        )\n        return vector_embedding.embeddings[0].values\n    \n    def _search_embedded_documents(self, query_embedding:list[float], n:int)->list[str]:\n        print(f' - CALL: search_embedded_documents(n = {n})')\n        results = collection.query(\n            query_embeddings=[query_embedding],\n            n_results=n\n        )\n        return results\n    \n    def _retrieve_documents(self, doc_ids:list[int])-> list[dict]:\n        print(f' - CALL: retrieve_documents(IDS = {doc_ids})')\n        papers_retrieved = []\n        for doc_id in doc_ids:\n            papers_retrieved.append(papers[doc_id])\n            \n        return papers_retrieved\n        \n    def _generate_final_answer(self,question: str, user_document: str, search_output: str, extended_info: str):\n        instruction = \"\"\"\n            You are an advanced scientific research assistant tasked with providing comprehensive answers based on retrieved academic papers.\n            \n            CONTEXT:\n            - The user has asked a QUESTION about a scientific topic\n            - They've provided their own INPUT_DOCUMENT (a scientific paper or research proposal)\n            - You've retrieved relevant papers from a scientific database (EMBED_DATA and EXTENDED_PAPER_INFO)\n            \n            YOUR TASK:\n            1. Analyze the retrieved papers and determine their relevance to the question\n            2. Provide an answer based on the retreived papers from EMBED_DATA and EXTENDED_PAPER_INFO. \n            3. You may use information from the INPUT_DOCUMENT if the papers from EMBED_DATA and EXTENDED_PAPER_INFO are not relevant. Always mention where the information is obtained from.\n            \n            IMPORTANT GUIDELINES:\n            - SKIP the user's own paper if it appears in the results\n            - Prioritize recent papers and high-impact findings\n            - Compare and contrast contradictory findings when present\n            - Always provide authors and publication dates\n            - Focus on scientific significance rather than general summaries\n            - For methodology questions, emphasize technical details and implementation\n            - Use objective, academically-appropriate language\n            - Provide the answer in a Markdown format\n            - You do not need to show all the papers from EMBED_DATA and EXTENDED_PAPER_INFO, only the most relevant and important\n            - For the answer, use only papers from the database. You may include some suggestions to other papers but don't make it too extensive.\n            - If the numer of papers is explicit in the QUESTION, show only the amount asked\n            - Do not mention the amount of papers retrieved from EMBED_DATA and EXTENDED_PAPER_INFO\n            \"\"\"\n\n        if user_document != None:\n            prompt =f\"\"\"\n                    QUESTION:{user_message}\n                    EMBED_DATA: {search_output}\n                    EXTENDED_PAPER_INFO: {extended_info}\n                    \"\"\"\n        else: \n            prompt =f\"\"\"\n                    QUESTION:{user_message}\n                    INPUT_DOCUMENT:{user_document}\n                    EMBED_DATA: {search_output}\n                    EXTENDED_PAPER_INFO: {extended_info}\n                    \"\"\"\n        \n        contents = []\n        contents.append(types.Content(role=\"user\", parts=[types.Part(text = prompt)]))\n        response_final = client.models.generate_content(\n            model=\"gemini-2.0-flash\", \n            config=types.GenerateContentConfig(\n                system_instruction=instruction\n            ),\n            contents = contents\n        )\n        return response_final.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:28:42.943208Z","iopub.execute_input":"2025-04-13T19:28:42.943585Z","iopub.status.idle":"2025-04-13T19:28:42.958890Z","shell.execute_reply.started":"2025-04-13T19:28:42.943549Z","shell.execute_reply":"2025-04-13T19:28:42.957948Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"## Example Usage 1\nFind scientific papers related to an input paper.","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Markdown, Latex\n\n\ndocument = \"/kaggle/input/unc-paper/2409.10655v2.pdf\"\nuser_message = \"Find me related papers with emphasis in uncertainty estimation.\"\n\nchatbot = RAG_Scientific_chatbot()\nanswer = chatbot.chat(user_message, document)\ndisplay(Markdown(answer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:28:46.608594Z","iopub.execute_input":"2025-04-13T19:28:46.609016Z","iopub.status.idle":"2025-04-13T19:28:50.725018Z","shell.execute_reply.started":"2025-04-13T19:28:46.608979Z","shell.execute_reply":"2025-04-13T19:28:50.723698Z"}},"outputs":[{"name":"stdout","text":" - CALL: create_embedding(Deep Reinforcement L...)\n - CALL: search_embedded_documents(n = 8)\n - CALL: retrieve_documents(IDS = [3972, 8390, 5911, 1186, 2009, 7951, 9861, 4252])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here are some papers that focus on uncertainty estimation in the context of reinforcement learning and decision-making:\n\n1.  **Active operator learning with predictive uncertainty quantification for partial differential equations** by Winovich et al. (2025): This paper introduces a method for uncertainty quantification in deep operator networks (DeepONets). It uses predictive uncertainty estimates calibrated to model errors observed during training. The framework uses a single network, unlike ensemble approaches, and adds minimal overhead during training and inference. The authors demonstrate the model's ability to accurately reproduce solutions to partial differential equations (PDEs) and show that predictive uncertainties align well with observed error distributions. They also demonstrate the use of predictive uncertainties within an active learning framework to improve accuracy and data efficiency.\n\n2.  **Robust Losses for Decision-Focused Learning** by Schutte et al. (2024): This paper addresses the challenge of uncertain parameters in optimization models for discrete decisions. The authors evaluate the effect of aleatoric and epistemic uncertainty on the accuracy of empirical regret as a surrogate loss. They propose three novel loss functions that approximate expected regret more robustly, improving test-sample empirical regret while maintaining equivalent computational time.\n\n3.  **Risk-Averse Offline Reinforcement Learning** by Armengol Urpí et al. (2021): This paper introduces the Offline Risk-Averse Actor-Critic (O-RAAC) algorithm, which learns risk-averse policies in a fully offline setting. The algorithm optimizes a risk-averse criterion, namely the CVaR (Conditional Value at Risk). The authors show that O-RAAC learns policies with higher CVaR than risk-neutral approaches and guarantees distributional robustness of the average performance with respect to particular distribution shifts."},"metadata":{}}],"execution_count":48},{"cell_type":"markdown","source":"## Example Usage 2\nSearch papers related to a topic and specify the amount of documents. ","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Markdown, Latex\n\nuser_message = \"I am looking for papers 6 that investigate robotics and machine learning.\"\n\nchatbot = RAG_Scientific_chatbot()\nanswer = chatbot.chat(user_message)\ndisplay(Markdown(answer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:27:27.080562Z","iopub.execute_input":"2025-04-13T19:27:27.080943Z","iopub.status.idle":"2025-04-13T19:27:30.762331Z","shell.execute_reply.started":"2025-04-13T19:27:27.080911Z","shell.execute_reply":"2025-04-13T19:27:30.761301Z"}},"outputs":[{"name":"stdout","text":" - CALL: create_embedding(Robotics, machine le...)\n - CALL: search_embedded_documents(n = 6)\n - CALL: retrieve_documents(IDS = [7594, 8488, 5513, 7069, 1494, 8950])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here are 6 papers that investigate robotics and machine learning:\n\n1.  **Deep Learning for Image and Point Cloud Fusion in Autonomous Driving: A Review** by Cui et al. (2021) reviews recent deep-learning-based data fusion approaches that leverage both image and point cloud data. The paper gives an overview of deep learning on image and point cloud data processing, camera-LiDAR fusion methods in depth completion, object detection, semantic segmentation, tracking and online cross-sensor calibration. The authors compare these methods on publicly available datasets and identify gaps and over-looked challenges between current academic researches and real-world applications.\n2.  **Smart systems, the fourth industrial revolution and new challenges in distributed computing** by El Baz and Zhu (2019) addresses smart systems and the smart world concept in the framework of the fourth industrial revolution, considers new challenges in distributed autonomous robots and computing, and illustrates a new kind of smart and reconfigurable distributed modular robot system.\n3.  **The Limits and Potentials of Deep Learning for Robotics** by Sünderhauf et al. (2018) discusses robotics-specific learning, reasoning, and embodiment challenges for deep learning. The authors explain the need for better evaluation metrics, highlight the importance and unique challenges for deep robotic learning in simulation, and explore the spectrum between purely data-driven and model-driven approaches.\n4.  **Online Constrained Model-based Reinforcement Learning** by Van Niekerk et al. (2017) proposes a model based approach that combines Gaussian Process regression and Receding Horizon Control to handle continuous state and action spaces while remaining within a limited time and resource budget for safe operation in robotic systems.\n5.  **Shared Cross-Modal Trajectory Prediction for Autonomous Driving** by Choi et al. (2021) proposes a Cross-Modal Embedding framework that aims to benefit from the use of multiple input modalities to predict future trajectories of traffic agents in highly interactive environments. At training time, their model learns to embed a set of complementary features in a shared latent space by jointly optimizing the objective functions across different types of input data.\n6.  **Trajectory-Optimized Sensing for Active Search of Tissue Abnormalities in Robotic Surgery** by Salman et al. (2018) develops an approach for guiding robots to automatically localize and find the shapes of tumors and other stiff inclusions present in the anatomy using Gaussian processes to model the stiffness distribution and active learning to direct the palpation path of the robot.\n"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"# Limitations\nIf we search for x, y and z papers from three topics, the RAG cannot process this information. This is where an agent would be of great use, because it can call multiple times different functions and gather all the data one by one to provide an answer.\n\nBecause of this, an agent was partially developed but the automatic calling of functions did not work correctly. In the appendix, partial code for this agent can be found.\n\nFurthermore, it cannot open documents in other format than PDF. This is also a field for improvement.","metadata":{}},{"cell_type":"markdown","source":"## Appendix: Partial code for an AI Agent \n\nThis code is provided for future improvement, given that the implementation did not work.","metadata":{}},{"cell_type":"code","source":"# === Tool declarations ===\ncreate_embedding_tool = {\n    \"name\" : \"create_embedding\",\n    \"description\" : \"For a given text, generate the corresponding vector embedding.\",\n    \"parameters\" : {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n            \"text\": {\n                \"type\": \"STRING\",\n                \"description\": \"The input text to embed.\"\n            }\n        },\n        \"required\": [\"text\"]\n    }\n}\n\nsearch_embedded_documents_tool = {\n    \"name\" : \"search_embedded_documents\",\n    \"description\" : \"Search for similar documents using a query embedding.\",\n    \"parameters\" : {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n            \"query_embedding\": {\n                \"type\": \"ARRAY\",\n                \"items\": {\n                    \"type\": \"NUMBER\"  # O \"INTEGER\" si tus vectores son int (normalmente son floats)\n                },\n                \"description\": \"The vector embedding of the input query.\"\n            },\n            \"n\": {\n                \"type\": \"INTEGER\",\n                \"description\": \"Number of top similar documents to retrieve.\"\n            }\n        },\n        \"required\": [\"query_embedding\", \"n\"]\n    }\n}\n\nretrieve_documents_tool = {\n    \"name\" : \"retrieve_documents\",\n    \"description\" : \"Retrieve detailed information about a document using its ID.\",\n    \"parameters\" : {\n        \"type\": \"OBJECT\",\n        \"properties\": {\n            \"doc_id\": {\n                \"type\": \"INTEGER\",\n                \"description\": \"The ID of the paper/document.\"\n            }\n        },\n        \"required\": [\"doc_id\"]\n    }\n}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:03:01.497685Z","iopub.execute_input":"2025-04-13T19:03:01.497983Z","iopub.status.idle":"2025-04-13T19:03:01.504091Z","shell.execute_reply.started":"2025-04-13T19:03:01.497957Z","shell.execute_reply":"2025-04-13T19:03:01.503051Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#orchestration_tools  = types.Tool(function_declarations=[create_embedding_tool, search_embedded_documents_tool])\n\norchestration_tools  = types.Tool(function_declarations=[create_embedding_tool, search_embedded_documents_tool])\n\n\ninstruction = \"\"\"You are a helpful chatbot that can interact with a database of vector embeddings\nof scientific papers and a database with the papers extended information. You will take the users questions and documents andgenerate\n\nUse the following tools:\n    - create_embedding(text) to convert text into vector embeddings \n    - search_embedded_documents(query_embedding, n) to obtain n papers that are similar to the embedded query \nfrom the database of vector embeddings.\n\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:03:01.505212Z","iopub.execute_input":"2025-04-13T19:03:01.505525Z","iopub.status.idle":"2025-04-13T19:03:01.526796Z","shell.execute_reply.started":"2025-04-13T19:03:01.505489Z","shell.execute_reply":"2025-04-13T19:03:01.525754Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#tool_call = response.candidates[0].content.parts[0].function_call\n\n#if tool_call.name == \"create_embedding\":\n#    result = create_embedding(**tool_call.args)\n\n#function_response_part = types.Part.from_function_response(\n#    name=tool_call.name,\n#    response={\"result\": result},\n#)\n\n#contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=tool_call)])) # Append the model's function call message\n#contents.append(types.Content(role=\"user\", parts=[function_response_part])) # Append the function response\n#response = client.models.generate_content(\n#    model=\"gemini-2.0-flash\", \n#    config=types.GenerateContentConfig(\n#        system_instruction=instruction,\n#        tools=[orchestration_tools]\n#    ),\n#    contents = contents\n#)\n#print(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T19:03:01.528272Z","iopub.execute_input":"2025-04-13T19:03:01.528853Z","iopub.status.idle":"2025-04-13T19:03:01.547321Z","shell.execute_reply.started":"2025-04-13T19:03:01.528774Z","shell.execute_reply":"2025-04-13T19:03:01.546196Z"}},"outputs":[],"execution_count":15}]}