{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbb12a1e",
   "metadata": {
    "papermill": {
     "duration": 0.007792,
     "end_time": "2025-04-10T22:10:30.257316",
     "exception": false,
     "start_time": "2025-04-10T22:10:30.249524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup\n",
    "Import and install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da0f1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:10:30.269131Z",
     "iopub.status.busy": "2025-04-10T22:10:30.268696Z",
     "iopub.status.idle": "2025-04-10T22:11:26.178778Z",
     "shell.execute_reply": "2025-04-10T22:11:26.177444Z"
    },
    "papermill": {
     "duration": 55.918461,
     "end_time": "2025-04-10T22:11:26.181388",
     "exception": false,
     "start_time": "2025-04-10T22:10:30.262927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.4/188.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.9/454.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\r\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mCollecting pymupdf\r\n",
      "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\r\n",
      "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pymupdf\r\n",
      "Successfully installed pymupdf-1.25.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n",
    "!pip install -qU \"google-genai==1.7.0\" \"chromadb==0.6.3\"\n",
    "!pip install --upgrade pymupdf\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc895c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:26.201464Z",
     "iopub.status.busy": "2025-04-10T22:11:26.200867Z",
     "iopub.status.idle": "2025-04-10T22:11:26.665972Z",
     "shell.execute_reply": "2025-04-10T22:11:26.664856Z"
    },
    "papermill": {
     "duration": 0.476195,
     "end_time": "2025-04-10T22:11:26.668072",
     "exception": false,
     "start_time": "2025-04-10T22:11:26.191877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API keys\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "#for m in client.models.list():\n",
    "#    if \"embedContent\" in m.supported_actions:\n",
    "#        print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458de28d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:26.685582Z",
     "iopub.status.busy": "2025-04-10T22:11:26.685209Z",
     "iopub.status.idle": "2025-04-10T22:11:26.946964Z",
     "shell.execute_reply": "2025-04-10T22:11:26.945948Z"
    },
    "papermill": {
     "duration": 0.272951,
     "end_time": "2025-04-10T22:11:26.948965",
     "exception": false,
     "start_time": "2025-04-10T22:11:26.676014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a retry policy. The model might make multiple consecutive calls automatically\n",
    "# for a complex query, this ensures the client retries if it hits quota limits.\n",
    "from google.api_core import retry\n",
    "\n",
    "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "if not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n",
    "  genai.models.Models.generate_content = retry.Retry(\n",
    "      predicate=is_retriable)(genai.models.Models.generate_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb13ba57",
   "metadata": {
    "papermill": {
     "duration": 0.00832,
     "end_time": "2025-04-10T22:11:26.965167",
     "exception": false,
     "start_time": "2025-04-10T22:11:26.956847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Upload of Arxiv papers\n",
    "First import the arxiv dataset and then perform vector embedding of all the documents. After the vector embedding, it is saved in a chromadb vector database. The arxiv dataset import is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b7068d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:26.982925Z",
     "iopub.status.busy": "2025-04-10T22:11:26.982394Z",
     "iopub.status.idle": "2025-04-10T22:11:27.008134Z",
     "shell.execute_reply": "2025-04-10T22:11:27.006871Z"
    },
    "papermill": {
     "duration": 0.036838,
     "end_time": "2025-04-10T22:11:27.009974",
     "exception": false,
     "start_time": "2025-04-10T22:11:26.973136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'versions', 'update_date', 'authors_parsed']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "amount_papers = 100\n",
    "papers = []\n",
    "with open('/kaggle/input/arxiv/arxiv-metadata-oai-snapshot.json', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= amount_papers:\n",
    "            break\n",
    "        papers.append(json.loads(line))\n",
    "\n",
    "# Now data is a list of dictionaries\n",
    "print(\"Headers:\", list(papers[0].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e7ebe",
   "metadata": {
    "papermill": {
     "duration": 0.00744,
     "end_time": "2025-04-10T22:11:27.025697",
     "exception": false,
     "start_time": "2025-04-10T22:11:27.018257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Only the title and the abstract of each paper will be embedded. The code below implements this preprocessing of the papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7083124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:27.043170Z",
     "iopub.status.busy": "2025-04-10T22:11:27.042815Z",
     "iopub.status.idle": "2025-04-10T22:11:27.049381Z",
     "shell.execute_reply": "2025-04-10T22:11:27.048134Z"
    },
    "papermill": {
     "duration": 0.017873,
     "end_time": "2025-04-10T22:11:27.051305",
     "exception": false,
     "start_time": "2025-04-10T22:11:27.033432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAPER TITLE: Calculation of prompt diphoton production cross sections at Tevatron and   LHC energies\n",
      "PAPER CONTENT:   A fully differential calculation in perturbative quantum chromodynamics is presented for the production of massive photon pairs at hadron colliders. All next-to-leading order perturbative contributions from quark-antiquark, gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as all-orders resummation of initial-state gluon radiation valid at next-to-next-to-leading logarithmic accuracy. The region of phase space is specified in which the calculation is most reliable. Good agreement is demonstrated with data from the Fermilab Tevatron, and predictions are made for more detailed tests with CDF and DO data. Predictions are shown for distributions of diphoton pairs produced at the energy of the Large Hadron Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs boson are contrasted with those produced from QCD processes at the LHC, showing that enhanced sensitivity to the signal can be obtained with judicious selection of events. \n"
     ]
    }
   ],
   "source": [
    "def remove_newlines(obj):\n",
    "    if isinstance(obj, str):\n",
    "        return obj.replace('\\n', ' ')\n",
    "        \n",
    "preprocessed_papers = []\n",
    "for paper in papers:\n",
    "    preprocessed_papers.append(\"PAPER TITLE: \" + remove_newlines(paper[\"title\"]) + \"\\nPAPER CONTENT: \"+ remove_newlines(paper[\"abstract\"]))\n",
    "print(preprocessed_papers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14e176",
   "metadata": {
    "papermill": {
     "duration": 0.00771,
     "end_time": "2025-04-10T22:11:27.067262",
     "exception": false,
     "start_time": "2025-04-10T22:11:27.059552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now the preprocessed papers are transformed into vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96fd8e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:27.084531Z",
     "iopub.status.busy": "2025-04-10T22:11:27.084147Z",
     "iopub.status.idle": "2025-04-10T22:11:28.125475Z",
     "shell.execute_reply": "2025-04-10T22:11:28.124012Z"
    },
    "papermill": {
     "duration": 1.052555,
     "end_time": "2025-04-10T22:11:28.127555",
     "exception": false,
     "start_time": "2025-04-10T22:11:27.075000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESSFULLY EMBEDDED 100 PAPERS\n"
     ]
    }
   ],
   "source": [
    "def batch(iterable, n=100):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i + n]\n",
    "\n",
    "# Example usage:\n",
    "papers_embedded = []  # Your list of inputs to embed\n",
    "papers_batches = list(batch(preprocessed_papers, 100))\n",
    "\n",
    "for batch in papers_batches:\n",
    "    batch_embedded = client.models.embed_content(\n",
    "        model='models/text-embedding-004',\n",
    "        contents=batch,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'))\n",
    "    list_batch_embedded = [e.values for e in batch_embedded.embeddings]\n",
    "    papers_embedded+=list_batch_embedded\n",
    "\n",
    "print(\"SUCCESSFULLY EMBEDDED \"+ str(len(papers_embedded)) + \" PAPERS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86af6e7",
   "metadata": {
    "papermill": {
     "duration": 0.0086,
     "end_time": "2025-04-10T22:11:28.144766",
     "exception": false,
     "start_time": "2025-04-10T22:11:28.136166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Once the vector embeddings of the papers are computed, these are stored into the chromadb database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "577e0198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:28.163089Z",
     "iopub.status.busy": "2025-04-10T22:11:28.162629Z",
     "iopub.status.idle": "2025-04-10T22:11:29.479730Z",
     "shell.execute_reply": "2025-04-10T22:11:29.478416Z"
    },
    "papermill": {
     "duration": 1.328432,
     "end_time": "2025-04-10T22:11:29.481684",
     "exception": false,
     "start_time": "2025-04-10T22:11:28.153252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESSFULLY UPLOADED 100 PAPERS\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "def batch(iterable, batch_size):\n",
    "    for i in range(0, len(iterable), batch_size):\n",
    "        yield iterable[i:i + batch_size]\n",
    "\n",
    "\n",
    "# Start ChromaDB client\n",
    "chromadb_client = chromadb.Client()\n",
    "\n",
    "# Create or get a collection\n",
    "collection = chromadb_client.get_or_create_collection(name=\"papers\")\n",
    "\n",
    "# Add the documents + embeddings to Chroma\n",
    "emb_batches = list(batch(papers_embedded, 41000))\n",
    "papers_batches = list(batch(preprocessed_papers, 41000))\n",
    "for i in range(len(emb_batches)):\n",
    "    ids_batch = [f\"doc_{j + i * 41000}\" for j in range(len(emb_batches[i]))]\n",
    "    collection.add(\n",
    "        documents=papers_batches[i],\n",
    "        embeddings=emb_batches[i],\n",
    "        ids=ids_batch,\n",
    "    )\n",
    "print(\"SUCCESSFULLY UPLOADED \"+ str(len(papers_embedded)) + \" PAPERS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8856e8aa",
   "metadata": {
    "papermill": {
     "duration": 0.008772,
     "end_time": "2025-04-10T22:11:29.498706",
     "exception": false,
     "start_time": "2025-04-10T22:11:29.489934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Vector database search example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0df25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:29.516335Z",
     "iopub.status.busy": "2025-04-10T22:11:29.515920Z",
     "iopub.status.idle": "2025-04-10T22:11:29.923281Z",
     "shell.execute_reply": "2025-04-10T22:11:29.922093Z"
    },
    "papermill": {
     "duration": 0.418735,
     "end_time": "2025-04-10T22:11:29.925420",
     "exception": false,
     "start_time": "2025-04-10T22:11:29.506685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_input = \"Statistical modeling of experimental physical laws is based on the probability density function of measured variables. It is expressed by experimental data via a kernel estimator. The kernel is determined objectively by the scattering of data during calibration of experimental setup. A physical law, which relates measured variables, is optimally extracted from experimental data by the conditional average estimator. It is derived directly from the kernel estimator and corresponds to a general nonparametric regression. T\"\n",
    "#query_input = pdf_text\n",
    "\n",
    "query_embedding = client.models.embed_content(\n",
    "        model='models/text-embedding-004',\n",
    "        contents=query_input,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3eaed6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:29.943381Z",
     "iopub.status.busy": "2025-04-10T22:11:29.943009Z",
     "iopub.status.idle": "2025-04-10T22:11:29.956918Z",
     "shell.execute_reply": "2025-04-10T22:11:29.955570Z"
    },
    "papermill": {
     "duration": 0.025527,
     "end_time": "2025-04-10T22:11:29.959192",
     "exception": false,
     "start_time": "2025-04-10T22:11:29.933665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: doc_88\n",
      "PAPER TITLE: A general approach to statistical modeling of physical laws:   nonparametric regression\n",
      "PAPER CONTENT:   Statistical modeling of experimental physical laws is based on the probability density function of measured variables. It is expressed by experimental data via a kernel estimator. The kernel is determined objectively by the scattering of data during calibration of experimental setup. A physical law, which relates measured variables, is optimally extracted from experimental data by the conditional average estimator. It is derived directly from the kernel estimator and corresponds to a general nonparametric regression. The proposed method is demonstrated by the modeling of a return map of noisy chaotic data. In this example, the nonparametric regression is used to predict a future value of chaotic time series from the present one. The mean predictor error is used in the definition of predictor quality, while the redundancy is expressed by the mean square distance between data points. Both statistics are used in a new definition of predictor cost function. From the minimum of the predictor cost function, a proper number of data in the model is estimated. \n",
      "\n",
      "ID: doc_39\n",
      "PAPER TITLE: Multilinear function series in conditionally free probability with   amalgamation\n",
      "PAPER CONTENT:   As in the cases of freeness and monotonic independence, the notion of conditional freeness is meaningful when complex-valued states are replaced by positive conditional expectations. In this framework, the paper presents several positivity results, a version of the central limit theorem and an analogue of the conditionally free R-transform constructed by means of multilinear function series. \n",
      "\n",
      "ID: doc_21\n",
      "PAPER TITLE: Stochastic Lie group integrators\n",
      "PAPER CONTENT:   We present Lie group integrators for nonlinear stochastic differential equations with non-commutative vector fields whose solution evolves on a smooth finite dimensional manifold. Given a Lie group action that generates transport along the manifold, we pull back the stochastic flow on the manifold to the Lie group via the action, and subsequently pull back the flow to the corresponding Lie algebra via the exponential map. We construct an approximation to the stochastic flow in the Lie algebra via closed operations and then push back to the Lie group and then to the manifold, thus ensuring our approximation lies in the manifold. We call such schemes stochastic Munthe-Kaas methods after their deterministic counterparts. We also present stochastic Lie group integration schemes based on Castell--Gaines methods. These involve using an underlying ordinary differential integrator to approximate the flow generated by a truncated stochastic exponential Lie series. They become stochastic Lie group integrator schemes if we use Munthe-Kaas methods as the underlying ordinary differential integrator. Further, we show that some Castell--Gaines methods are uniformly more accurate than the corresponding stochastic Taylor schemes. Lastly we demonstrate our methods by simulating the dynamics of a free rigid body such as a satellite and an autonomous underwater vehicle both perturbed by two independent multiplicative stochastic noise processes. \n",
      "\n",
      "ID: doc_46\n",
      "PAPER TITLE: Intelligent location of simultaneously active acoustic emission sources:   Part I\n",
      "PAPER CONTENT:   The intelligent acoustic emission locator is described in Part I, while Part II discusses blind source separation, time delay estimation and location of two simultaneously active continuous acoustic emission sources.   The location of acoustic emission on complicated aircraft frame structures is a difficult problem of non-destructive testing. This article describes an intelligent acoustic emission source locator. The intelligent locator comprises a sensor antenna and a general regression neural network, which solves the location problem based on learning from examples. Locator performance was tested on different test specimens. Tests have shown that the accuracy of location depends on sound velocity and attenuation in the specimen, the dimensions of the tested area, and the properties of stored data. The location accuracy achieved by the intelligent locator is comparable to that obtained by the conventional triangulation method, while the applicability of the intelligent locator is more general since analysis of sonic ray paths is avoided. This is a promising method for non-destructive testing of aircraft frame structures by the acoustic emission method. \n",
      "\n",
      "ID: doc_85\n",
      "PAPER TITLE: Clustering in a stochastic model of one-dimensional gas\n",
      "PAPER CONTENT:   We give a quantitative analysis of clustering in a stochastic model of one-dimensional gas. At time zero, the gas consists of $n$ identical particles that are randomly distributed on the real line and have zero initial speeds. Particles begin to move under the forces of mutual attraction. When particles collide, they stick together forming a new particle, called cluster, whose mass and speed are defined by the laws of conservation. We are interested in the asymptotic behavior of $K_n(t)$ as $n\\to \\infty$, where $K_n(t)$ denotes the number of clusters at time $t$ in the system with $n$ initial particles. Our main result is a functional limit theorem for $K_n(t)$. Its proof is based on the discovered localization property of the aggregation process, which states that the behavior of each particle is essentially defined by the motion of neighbor particles. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding.embeddings[0].values],\n",
    "    n_results=5  # Number of similar docs to return\n",
    ")\n",
    "\n",
    "for doc, doc_id in zip(results[\"documents\"][0], results[\"ids\"][0]):\n",
    "    print(f\"ID: {doc_id}\")\n",
    "    print(f\"{doc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5948a",
   "metadata": {
    "papermill": {
     "duration": 0.007888,
     "end_time": "2025-04-10T22:11:29.975248",
     "exception": false,
     "start_time": "2025-04-10T22:11:29.967360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GENAI AGENT\n",
    "Now an AI agent is created where an LLM interacts with the user input and searches through the papers database to answer the scientific-paper related question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5d322",
   "metadata": {
    "papermill": {
     "duration": 0.008663,
     "end_time": "2025-04-10T22:11:29.991902",
     "exception": false,
     "start_time": "2025-04-10T22:11:29.983239",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Orchestration functions\n",
    "The orchestrator is composed of the following functions:\n",
    "\n",
    "- create_embedding(text): For a given text generates the corresponding vector embedding.\n",
    "- search_embedded_documents(query_embedding, n): For a given vector, searches nearby vectors in the vector embeddings database.\n",
    "- retrieve_documents(doc_id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8200602e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:30.014354Z",
     "iopub.status.busy": "2025-04-10T22:11:30.013976Z",
     "iopub.status.idle": "2025-04-10T22:11:30.024922Z",
     "shell.execute_reply": "2025-04-10T22:11:30.023836Z"
    },
    "papermill": {
     "duration": 0.022543,
     "end_time": "2025-04-10T22:11:30.026793",
     "exception": false,
     "start_time": "2025-04-10T22:11:30.004250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# === Tools ===\n",
    "def create_embedding(text)-> list:\n",
    "    print(f' - CALL: create_embedding({text[:20]})')\n",
    "    vector_embedding = client.models.embed_content(\n",
    "        model='models/text-embedding-004',\n",
    "        contents=text,\n",
    "        config=types.EmbedContentConfig(task_type='SEMANTIC_SIMILARITY')\n",
    "    )\n",
    "    return vector_embedding.embeddings[0].values\n",
    "\n",
    "def search_embedded_documents(query_embedding:list[float], n:int)->list[str]:\n",
    "    print(f' - CALL: search_embedded_documents(n = {n})')\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def retrieve_documents(doc_ids:list[int])-> list[dict]:\n",
    "    print(f' - CALL: retrieve_documents(IDS = {doc_ids})')\n",
    "    papers_retrieved = []\n",
    "    for doc_id in doc_ids:\n",
    "        papers_retrieved.append(papers[doc_id])\n",
    "        \n",
    "    return papers_retrieved\n",
    "\n",
    "\n",
    "# === Tool declarations ===\n",
    "create_embedding_tool = {\n",
    "    \"name\" : \"create_embedding\",\n",
    "    \"description\" : \"For a given text, generate the corresponding vector embedding.\",\n",
    "    \"parameters\" : {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"text\": {\n",
    "                \"type\": \"STRING\",\n",
    "                \"description\": \"The input text to embed.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"text\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "search_embedded_documents_tool = {\n",
    "    \"name\" : \"search_embedded_documents\",\n",
    "    \"description\" : \"Search for similar documents using a query embedding.\",\n",
    "    \"parameters\" : {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"query_embedding\": {\n",
    "                \"type\": \"ARRAY\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"NUMBER\"  # O \"INTEGER\" si tus vectores son int (normalmente son floats)\n",
    "                },\n",
    "                \"description\": \"The vector embedding of the input query.\"\n",
    "            },\n",
    "            \"n\": {\n",
    "                \"type\": \"INTEGER\",\n",
    "                \"description\": \"Number of top similar documents to retrieve.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query_embedding\", \"n\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "retrieve_documents_tool = {\n",
    "    \"name\" : \"retrieve_documents\",\n",
    "    \"description\" : \"Retrieve detailed information about a document using its ID.\",\n",
    "    \"parameters\" : {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"doc_id\": {\n",
    "                \"type\": \"INTEGER\",\n",
    "                \"description\": \"The ID of the paper/document.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"doc_id\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d6f477",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:30.044339Z",
     "iopub.status.busy": "2025-04-10T22:11:30.043714Z",
     "iopub.status.idle": "2025-04-10T22:11:30.049583Z",
     "shell.execute_reply": "2025-04-10T22:11:30.048440Z"
    },
    "papermill": {
     "duration": 0.016884,
     "end_time": "2025-04-10T22:11:30.051815",
     "exception": false,
     "start_time": "2025-04-10T22:11:30.034931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#orchestration_tools  = types.Tool(function_declarations=[create_embedding_tool, search_embedded_documents_tool])\n",
    "\n",
    "orchestration_tools  = types.Tool(function_declarations=[create_embedding_tool, search_embedded_documents_tool])\n",
    "\n",
    "\n",
    "instruction = \"\"\"You are a helpful chatbot that can interact with a database of vector embeddings\n",
    "of scientific papers and a database with the papers extended information. You will take the users questions and documents andgenerate\n",
    "\n",
    "Use the following tools:\n",
    "    - create_embedding(text) to convert text into vector embeddings \n",
    "    - search_embedded_documents(query_embedding, n) to obtain n papers that are similar to the embedded query \n",
    "from the database of vector embeddings.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c84a3ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:30.069223Z",
     "iopub.status.busy": "2025-04-10T22:11:30.068817Z",
     "iopub.status.idle": "2025-04-10T22:11:30.660949Z",
     "shell.execute_reply": "2025-04-10T22:11:30.659730Z"
    },
    "papermill": {
     "duration": 0.603516,
     "end_time": "2025-04-10T22:11:30.663356",
     "exception": false,
     "start_time": "2025-04-10T22:11:30.059840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    text = \"\"\n",
    "    with pymupdf.open(path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"/kaggle/input/unc-paper/2409.10655v2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c97259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:11:30.681859Z",
     "iopub.status.busy": "2025-04-10T22:11:30.681459Z",
     "iopub.status.idle": "2025-04-10T22:12:05.964717Z",
     "shell.execute_reply": "2025-04-10T22:12:05.963622Z"
    },
    "papermill": {
     "duration": 35.295076,
     "end_time": "2025-04-10T22:12:05.966721",
     "exception": false,
     "start_time": "2025-04-10T22:11:30.671645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_document = pdf_text[:1000]\n",
    "user_message = \"Find me related papers.\"\n",
    "\n",
    "instruction = \"\"\"You are a helpful chatbot that processes inputs from users and generates an output text based on the user requirements. This output text is going to be used to be used to do vector search in a database of vector embedded papers.\"\"\"\n",
    "\n",
    "contents = [\n",
    "    types.Content(\n",
    "        role=\"user\", parts=[types.Part(text=user_message),types.Part(text=pdf_text)]\n",
    "    )\n",
    "]\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=instruction,\n",
    "        tools=[orchestration_tools]\n",
    "    ),\n",
    "    contents = contents\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10fb89bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:12:05.984665Z",
     "iopub.status.busy": "2025-04-10T22:12:05.984299Z",
     "iopub.status.idle": "2025-04-10T22:12:08.201653Z",
     "shell.execute_reply": "2025-04-10T22:12:08.200212Z"
    },
    "papermill": {
     "duration": 2.228415,
     "end_time": "2025-04-10T22:12:08.203688",
     "exception": false,
     "start_time": "2025-04-10T22:12:05.975273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - CALL: create_embedding()\n",
      " - CALL: search_embedded_documents(n = 5)\n",
      " - CALL: retrieve_documents(IDS = [89, 90, 91, 92])\n",
      "The following papers are related to your input document based on the content:\n",
      "\n",
      "1.  **Intelligent location of simultaneously active acoustic emission sources: Part I** by Unknown Authors: This paper describes an intelligent acoustic emission source locator comprising a sensor antenna and a general regression neural network for solving location problems based on learning from examples. The locator's performance was tested on different test specimens, and the location accuracy was comparable to that of the conventional triangulation method.\n",
      "\n",
      "2.  **General System theory, Like-Quantum Semantics and Fuzzy Sets** by Unknown Authors: This paper explores the possibility of extending the quantum formalism in relation to the requirements of the general systems theory by using a quantum semantics arising from the deep logical structure of quantum theory, considering the truth-values of quantum propositions within the context of fuzzy sets.\n",
      "\n",
      "3.  **Real Options for Project Schedules (ROPS)** by Lester Ingber: This paper introduces Real Options for Project Schedules (ROPS), which has three recursive sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA) optimization shell optimizes parameters of strategic Plans containing multiple Projects containing ordered Tasks.\n",
      "\n",
      "4.  **Visualizing Teleportation** by Unknown Authors: This paper describes a novel way of picturing the processing of quantum information, allowing a direct visualization of teleportation of quantum states and providing a simple and intuitive understanding of this phenomenon.\n",
      "\n",
      "5.  **Some new experimental photonic flame effect features** by Unknown Authors: This paper presents the results of the spectral, energetical, and temporal characteristics of radiation in the presence of the photonic flame effect.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding = create_embedding(response.text)\n",
    "search_output = search_embedded_documents(embedding, 5)\n",
    "extended_info = retrieve_documents([89,90,91,92])\n",
    "\n",
    "instruction = \"\"\" You are a helpful chatbot that researched on a papers databased and obtained related papers. Answer the first user query with the found papers\"\"\"\n",
    "instruction = \"\"\"You are a helpful chatbot that uses retrieval augmented generation to answer questions regarding scientific papers. The user provided a QUESTION and an INPUT_DOCUMENT. \n",
    "                The information retreived from the database is composed of: \n",
    "                - EMBED_DATA: Shows the documents obtained after a vector search from the embedding of QUESTION and INPUT_DOCUMENT and the database.\n",
    "                - EXTENDED_PAPER_INFO: Shows more information of the papers from EMBED_DATA.\n",
    "\n",
    "                Answer the user QUESTION using the EMBED_DATA and EXTENDED_PAPER_INFO. IF the EMBED_DATA has the paper from INPUT_DOCUMENT, skip the paper in the answer.\n",
    "                \n",
    "                \"\"\"\n",
    "\n",
    "prompt =f\"\"\"\n",
    "        QUESTION:{user_message}\n",
    "        INPUT_DOCUMENT:{user_document}\n",
    "        EMBED_DATA: {search_output}\n",
    "        EXTENDED_PAPER_INFO: {extended_info}\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "contents = []\n",
    "contents.append(types.Content(role=\"user\", parts=[types.Part(text = prompt)]))\n",
    "response_final = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=instruction\n",
    "        #tools=[orchestration_tools]\n",
    "    ),\n",
    "    contents = contents\n",
    ")\n",
    "print(response_final.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7090ffa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-10T22:12:08.221521Z",
     "iopub.status.busy": "2025-04-10T22:12:08.221185Z",
     "iopub.status.idle": "2025-04-10T22:12:08.225478Z",
     "shell.execute_reply": "2025-04-10T22:12:08.224339Z"
    },
    "papermill": {
     "duration": 0.015015,
     "end_time": "2025-04-10T22:12:08.227115",
     "exception": false,
     "start_time": "2025-04-10T22:12:08.212100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tool_call = response.candidates[0].content.parts[0].function_call\n",
    "\n",
    "#if tool_call.name == \"create_embedding\":\n",
    "#    result = create_embedding(**tool_call.args)\n",
    "\n",
    "#function_response_part = types.Part.from_function_response(\n",
    "#    name=tool_call.name,\n",
    "#    response={\"result\": result},\n",
    "#)\n",
    "\n",
    "#contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=tool_call)])) # Append the model's function call message\n",
    "#contents.append(types.Content(role=\"user\", parts=[function_response_part])) # Append the function response\n",
    "#response = client.models.generate_content(\n",
    "#    model=\"gemini-2.0-flash\", \n",
    "#    config=types.GenerateContentConfig(\n",
    "#        system_instruction=instruction,\n",
    "#        tools=[orchestration_tools]\n",
    "#    ),\n",
    "#    contents = contents\n",
    "#)\n",
    "#print(response)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 612177,
     "sourceId": 11291024,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7088951,
     "sourceId": 11332325,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 102.647746,
   "end_time": "2025-04-10T22:12:09.157470",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-10T22:10:26.509724",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
